{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6d6232b-b3bc-486e-ab1d-615da23e4495",
   "metadata": {},
   "source": [
    "# Machine Learning Cookbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d6b43dc-0cfc-440c-966c-bf1842333dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inti pembelajaran\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sympy import Matrix\n",
    "from scipy import sparse\n",
    "from sklearn.datasets import *\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.pipeline import *\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.dummy import DummyRegressor, DummyClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import *\n",
    "\n",
    "# tambahan pengetahuan\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import unicodedata\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472b1fd9-1cae-4e6a-b9aa-881001997122",
   "metadata": {},
   "source": [
    "## 1. Vectors, Matrices, and Arrays\n",
    "\n",
    "<img src='https://miro.medium.com/max/914/1*KxW0S6_4v0FXmRvPUJwzMA.png'>\n",
    "NumPy is the foundation of the Python machine learning stack. NumPy allows for\n",
    "efficient operations on the data structures often used in machine learning: vectors,\n",
    "matrices, and tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10af4a6f-6040-46e0-bf8d-d5925e3eb44a",
   "metadata": {},
   "source": [
    "### 1.1 Membuat Vektor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c01c5e14-ecc3-4ace-98f9-0d2c9d671bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3]),\n",
       " array([[1],\n",
       "        [2],\n",
       "        [3]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vektor sebagai baris\n",
    "vector_row = np.array([1, 2, 3]) # or np.arange()\n",
    "\n",
    "# vektor sebagai kolom\n",
    "vector_column = np.array([[1],\n",
    "                          [2],\n",
    "                          [3]])\n",
    "\n",
    "vector_row, vector_column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4c9da2-acf4-4840-9d2a-0eefd3e7ac56",
   "metadata": {},
   "source": [
    "### 1.2 Membuat Matriks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "51df93c9-dd72-461e-b639-a5f5072215bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}1 & 2\\\\3 & 4\\\\5 & 6\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "Matrix([\n",
       "[1, 2],\n",
       "[3, 4],\n",
       "[5, 6]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = np.array([[1, 2],\n",
    "                   [3, 4],\n",
    "                   [5, 6]])\n",
    "Matrix(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c4ebac-327f-4bc5-9f26-1fcf79514f73",
   "metadata": {},
   "source": [
    "*NumPy actually has a dedicated matrix data structure:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e288de0e-2a9a-43cc-a796-1ae47f1a9c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_object = np.mat([[1, 2],\n",
    "                        [3, 4],\n",
    "                        [5, 6]])\n",
    "\n",
    "matrix_object "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be054a6-1c58-4514-b1bc-1e9b026f5740",
   "metadata": {},
   "source": [
    "However, the matrix data structure is not recommended for two reasons. First, arrays\n",
    "are the de facto standard data structure of NumPy. Second, the vast majority of\n",
    "NumPy operations return arrays, not matrix objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affecf8a-d0a7-4880-9a52-786ade8ca425",
   "metadata": {},
   "source": [
    "### 1.3 Membuat Sparse Matriks\n",
    "Sparse Data adalah data yang sebagian besar memiliki elemen yang tidak digunakan (elemen yang tidak membawa informasi apa pun)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd5c8d28-36e4-48ee-85d1-b147e62f0192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (1, 1)\t1\n",
      "  (2, 0)\t3\n"
     ]
    }
   ],
   "source": [
    "# matrix biasa\n",
    "matrix = np.array([[0, 0],\n",
    "                   [0, 1],\n",
    "                   [3, 0]])\n",
    "\n",
    "# create sparse matrix\n",
    "matrix_sparse = sparse.csr_matrix(matrix)\n",
    "\n",
    "print(matrix_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65ab2bb-fd8d-4305-8555-907ac6f3bdf5",
   "metadata": {},
   "source": [
    "data di atas dapat dibaca:\n",
    "* pada baris ke 1 kolom ke 1 terdapat nilai 1\n",
    "* pada baris ke 2 kolom ke 0 terdapat nilai 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ef8c79-bbcb-4c80-8424-4439c3ca20d9",
   "metadata": {},
   "source": [
    "### 1.4 Memilih Element pada Matriks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d28fe31e-33cd-4223-83c5-ab9c5cdf271b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# Create row vector\n",
    "vector = np.array([1, 2, 3, 4, 5, 6])\n",
    "\n",
    "# Create matrix\n",
    "matrix = np.array([[1, 2, 3],\n",
    "                   [4, 5, 6],\n",
    "                   [7, 8, 9]])\n",
    "\n",
    "# Select third element of vector\n",
    "print(vector[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "805c0358-cede-461c-a7c3-e8d973159019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "# Select second row, second column\n",
    "print(matrix[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b17d41dc-2a78-42e6-88f2-0673851794e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "# Select all elements of a vector\n",
    "print(vector[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7e4dea8-a07d-467e-9df6-596aafd6d739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n"
     ]
    }
   ],
   "source": [
    "# Select everything up to and including the third element\n",
    "print(vector[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1e92310e-1e37-45f1-b828-56bbc274534e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 5 6]\n"
     ]
    }
   ],
   "source": [
    "# Select everything after the third element\n",
    "print(vector[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0d207ae2-58e2-42e8-9245-26c375473c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# Select the last element\n",
    "print(vector[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e1a22368-170a-4363-bedd-a297f566f50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3 4]\n",
      " [5 6 7 8]]\n"
     ]
    }
   ],
   "source": [
    "# Select the first two rows and all columns of a matrix\n",
    "print(matrix[:2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff2e4d2b-23c6-437c-af6e-70d2b097e96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2]\n",
      " [ 6]\n",
      " [10]]\n"
     ]
    }
   ],
   "source": [
    "# Select all rows and the second column\n",
    "print(matrix[:,1:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a166cba6-833b-4a9b-aa64-198d54a400dd",
   "metadata": {},
   "source": [
    "### 1.5 Describing a Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e601875-6e6a-4357-86a8-02750ca3176b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}1 & 2 & 3 & 4\\\\5 & 6 & 7 & 8\\\\9 & 10 & 11 & 12\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "Matrix([\n",
       "[1,  2,  3,  4],\n",
       "[5,  6,  7,  8],\n",
       "[9, 10, 11, 12]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating matrix\n",
    "matrix = np.array([[1, 2, 3, 4],\n",
    "                   [5, 6, 7, 8],\n",
    "                   [9, 10, 11, 12]])\n",
    "\n",
    "Matrix(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbcbaaa2-39c4-4c4f-a761-8d51cc2f3a9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View number of rows and columns\n",
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da8e8b4f-89b6-42d8-8d00-53c41e28f7ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View number of elements (rows * columns)\n",
    "matrix.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7329699-f574-4906-8936-d92d04a5f6ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View number of dimensions\n",
    "matrix.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1797b3e-d32d-4d5e-b455-032fe67d7e8e",
   "metadata": {},
   "source": [
    "### 1.6 Applying Operations to Elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "68c0b8cf-10db-4ceb-b284-59eac1f475fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}1 & 2 & 3\\\\4 & 5 & 6\\\\7 & 8 & 9\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "Matrix([\n",
       "[1, 2, 3],\n",
       "[4, 5, 6],\n",
       "[7, 8, 9]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = np.array([[1, 2, 3],\n",
    "                   [4, 5, 6],\n",
    "                   [7, 8, 9]])\n",
    "\n",
    "Matrix(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d9418615-41d3-441f-a341-f77ac1fcdff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[101, 102, 103],\n",
       "       [104, 105, 106],\n",
       "       [107, 108, 109]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create function that adds 100 to something\n",
    "add_100 = lambda i: i + 100\n",
    "\n",
    "# Create vectorized function\n",
    "vectorized_add_100 = np.vectorize(add_100)\n",
    "\n",
    "# Apply function to all elements in matrix\n",
    "vectorized_add_100(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8f3631-1a73-4874-b89b-1db4de4fbedd",
   "metadata": {},
   "source": [
    "NumPy’s vectorize class converts a function into a function that can apply to all elements in an array or slice of an array. It’s worth noting that vectorize is essentially a\n",
    "for loop over the elements and does not increase performance. Furthermore, NumPy\n",
    "arrays allow us to perform operations between arrays even if their dimensions are not\n",
    "the same (a process called broadcasting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0d490fcb-39b0-472d-88ce-82e1e1c95f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[101, 102, 103],\n",
       "       [104, 105, 106],\n",
       "       [107, 108, 109]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add 100 to all elements\n",
    "matrix + 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb1b4ec-5327-4481-9d70-db64007ca192",
   "metadata": {},
   "source": [
    "### 1.7 Finding the Maximum and Minimum Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1609155e-33d5-4f26-b957-10197d8dcb57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}1 & 2 & 3\\\\4 & 5 & 6\\\\7 & 8 & 9\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "Matrix([\n",
       "[1, 2, 3],\n",
       "[4, 5, 6],\n",
       "[7, 8, 9]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = np.array([[1, 2, 3],\n",
    "                   [4, 5, 6],\n",
    "                   [7, 8, 9]])\n",
    "\n",
    "Matrix(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6a377813-de37-4641-84db-f2503e40c8dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return maximum element\n",
    "np.max(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c0da67e8-b7d6-41e1-ae75-1083d5b29565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return minimum element\n",
    "np.min(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86079fec-7f5a-4a73-a9f8-895fc6eef537",
   "metadata": {},
   "source": [
    "### 1.8 Average, Variance, and Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "61dea2c3-ed51-49cf-b9ae-98236628a480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}1 & 2 & 3\\\\4 & 5 & 6\\\\7 & 8 & 9\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "Matrix([\n",
       "[1, 2, 3],\n",
       "[4, 5, 6],\n",
       "[7, 8, 9]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Matrix(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "21521839-509c-482b-be9a-5fedb3d41e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return mean\n",
    "np.mean(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7bfa5708-6639-4914-a0d3-40d092e71d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4., 5., 6.])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the mean value in each column\n",
    "np.mean(matrix, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a892786a-77e2-4c34-b7ca-8f31cae6f3aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.666666666666667"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return variance\n",
    "np.var(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9bcf6d4a-2608-41fa-b2fd-f7624e0a647a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.581988897471611"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return standard deviation\n",
    "np.std(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cbf41c-1ef9-4015-a37a-07cf30aa6ee0",
   "metadata": {},
   "source": [
    "### 1.9 Reshaping Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d97c53a2-dadb-4165-b615-cf335136101d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}1 & 2 & 3\\\\4 & 5 & 6\\\\7 & 8 & 9\\\\10 & 11 & 12\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "Matrix([\n",
       "[ 1,  2,  3],\n",
       "[ 4,  5,  6],\n",
       "[ 7,  8,  9],\n",
       "[10, 11, 12]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create 4x3 matrix\n",
    "matrix = np.array([[1, 2, 3],\n",
    "                   [4, 5, 6],\n",
    "                   [7, 8, 9],\n",
    "                   [10, 11, 12]])\n",
    "\n",
    "Matrix(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9d754824-f78e-4f33-86b8-9586785503db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4,  5,  6],\n",
       "       [ 7,  8,  9, 10, 11, 12]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape matrix into 2x6 matrix\n",
    "matrix.reshape(2, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe2eef3-49e4-4887-a3c9-de6413ae052a",
   "metadata": {},
   "source": [
    "*One useful argument in reshape is -1, which effectively means “as many as needed,”\n",
    "so reshape(-1, 1) means one row and as many columns as needed:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d2c3551e-07c6-46d4-b355-2c9a724f66b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6a4485-b2ee-4945-927d-3a419ec72355",
   "metadata": {},
   "source": [
    "### 1.10 Transposing a Vector or Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80120903-d8ac-4e09-b513-a8778a209dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}1 & 2 & 3\\\\4 & 5 & 6\\\\7 & 8 & 9\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "Matrix([\n",
       "[1, 2, 3],\n",
       "[4, 5, 6],\n",
       "[7, 8, 9]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create matrix\n",
    "matrix = np.array([[1, 2, 3],\n",
    "                   [4, 5, 6],\n",
    "                   [7, 8, 9]])\n",
    "\n",
    "Matrix(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "288c0afc-402c-4fe9-922e-5793b8384547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 4, 7],\n",
       "       [2, 5, 8],\n",
       "       [3, 6, 9]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transpose matrix\n",
    "matrix.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08f6d96e-6d56-4051-9507-b4c433f9a063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 4, 7],\n",
       "       [2, 5, 8],\n",
       "       [3, 6, 9]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cara lain\n",
    "np.transpose(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d5a0f3eb-45a3-475d-ba75-0a98905772de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vektor tidak akan bisa ditranspose\n",
    "np.array([1, 2, 3, 4, 5, 6]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "447c47d9-e55d-4452-86a7-fd66301aa6d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4],\n",
       "       [5],\n",
       "       [6]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vektor baris menjadi vektor kolom\n",
    "np.array([[1, 2, 3, 4, 5, 6]]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2e9164-5dc6-4f1c-98d5-b76af22535a6",
   "metadata": {},
   "source": [
    "### 1.11 Flattening a Matrix\n",
    "transform a matrix into a one-dimensional array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8243e04c-265d-4fcf-9462-23cd7a498c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}1 & 2 & 3\\\\4 & 5 & 6\\\\7 & 8 & 9\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "Matrix([\n",
       "[1, 2, 3],\n",
       "[4, 5, 6],\n",
       "[7, 8, 9]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Matrix(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e4198f28-151d-4102-b3fb-3dcbb3604975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flatten matrix\n",
    "matrix.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "88b0b859-0e25-4a0f-a31c-e1df186830a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ravel matrix\n",
    "matrix.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771b39db-644b-4f0c-af98-2f92fcda2c8b",
   "metadata": {},
   "source": [
    "### 1.12 Calculating the Determinant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f398b4c0-f626-4fcc-979c-212b5e7004fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}1 & 2 & 3\\\\4 & 5 & 6\\\\7 & 8 & 9\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "Matrix([\n",
       "[1, 2, 3],\n",
       "[4, 5, 6],\n",
       "[7, 8, 9]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Matrix(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1d384d2f-8290-4898-9db6-c0da37303f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9.51619735392994e-16"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return determinant of matrix\n",
    "np.linalg.det(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962a4380-f74d-4b49-93eb-33e6c488a432",
   "metadata": {},
   "source": [
    "### 1.13 Getting the Diagonal of a Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bafb84c2-dc3a-4154-8b41-3b3310323269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}1 & 2 & 3\\\\4 & 5 & 6\\\\7 & 8 & 9\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "Matrix([\n",
       "[1, 2, 3],\n",
       "[4, 5, 6],\n",
       "[7, 8, 9]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Matrix(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "987c7e54-8b02-4034-9046-50e3291fb87b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 5, 9])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return diagonal elements\n",
    "matrix.diagonal()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdddd9ec-aaa3-4d9b-b0b7-b920bb861494",
   "metadata": {},
   "source": [
    "### 1.4  Calculating Dot Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "84e0ba92-30f8-49d4-b369-2fe6240eeac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two vectors\n",
    "vector_a = np.array([1,2,3])\n",
    "vector_b = np.array([4,5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fe1ca6bd-3f10-4844-aa35-01a3bd021cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate dot product\n",
    "# vector_a.dot(vector_b)\n",
    "np.dot(vector_a, vector_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a6389b67-774f-426b-a0ec-0cad2c0a11a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# another option\n",
    "vector_a @ vector_b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809cb1b0-4b0e-4a18-ae79-5e22bf1fc39c",
   "metadata": {},
   "source": [
    "### 1.15 Inverting a Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "adce683f-7e30-466f-b9bd-d1dc40bb213e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}5 & 2\\\\4 & 1\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "Matrix([\n",
       "[5, 2],\n",
       "[4, 1]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = np.array([[5, 2],\n",
    "                   [4, 1]])\n",
    "\n",
    "Matrix(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ddd06a22-b6df-43ac-be33-2e099db6ddea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.33333333,  0.66666667],\n",
       "       [ 1.33333333, -1.66666667]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate inverse of matrix\n",
    "np.linalg.inv(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4377a8b0-44cb-4ae4-992e-7842f0dc6099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiply matrix and its inverse\n",
    "matrix @ np.linalg.inv(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd95028-c935-41f6-8c75-d187b5962d20",
   "metadata": {},
   "source": [
    "### 1.16 Generating Random Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "38971ab9-5d9e-495c-9fd1-aed23bfb5959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5488135 , 0.71518937, 0.60276338])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set seed\n",
    "np.random.seed(0)\n",
    "\n",
    "# Generate three random floats between 0.0 and 1.0\n",
    "np.random.random(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d108eeab-461d-42ab-a17e-476888199f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 7, 9])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate three random integers between 1 and 10\n",
    "np.random.randint(0, 11, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "81d5b225-c219-42aa-9519-9c8565803111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.2683282 ,  1.33354538, -0.84272405])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Draw three numbers from a normal distribution with mean 0.0\n",
    "# and standard deviation of 1.0\n",
    "np.random.normal(0.0, 1.0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9ca5c513-3fb4-4db0-86a2-f22ff2fefcf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.10898075,  3.2778983 , -0.47496606])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Draw three numbers from a logistic distribution with mean 0.0 and scale of 1.0\n",
    "np.random.logistic(0.0, 1.0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "76b6bd78-6d83-44fd-9920-9a253d667946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.79172504, 1.52889492, 1.56804456])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Draw three numbers greater than or equal to 1.0 and less than 2.0\n",
    "np.random.uniform(1.0, 2.0, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48d4caa-3974-4cbe-80f1-b27de387ced9",
   "metadata": {},
   "source": [
    "## 2. Load Datasets\n",
    "The first step in any machine learning endeavor is to get the raw data into our system.\n",
    "The raw data might be a logfile, dataset file, or database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b4c504-57cd-40ad-84f3-79973dc1db74",
   "metadata": {},
   "source": [
    "### 2.1 Creating a Simulated Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08bbfcf6-fe4f-4d57-b1e5-c7c06d74cc3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanatory Matrix:\n",
      " [[ 1.29322588 -0.61736206 -0.11044703]\n",
      " [-2.793085    0.36633201  1.93752881]\n",
      " [ 0.80186103 -0.18656977  0.0465673 ]\n",
      " [ 0.12910158  0.50274088  1.6169496 ]\n",
      " [-0.69166075 -0.6871727  -0.39675353]]\n",
      "Response Vector:\n",
      " [ -10.37865986   25.5124503    19.67705609  149.50205427 -121.65210879]\n"
     ]
    }
   ],
   "source": [
    "# creating regression datasets\n",
    "explanatory, response, coeficients = make_regression(n_samples=100,\n",
    "                                                     n_features=3,\n",
    "                                                     n_informative=3,\n",
    "                                                     n_targets=1,\n",
    "                                                     noise=0.0,\n",
    "                                                     coef=True,\n",
    "                                                     random_state=1)\n",
    "\n",
    "# View feature matrix and target vector\n",
    "print('Explanatory Matrix:\\n', explanatory[:5])\n",
    "print('Response Vector:\\n', response[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f84b218-8f8e-423d-a066-357422021c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Matrix:\n",
      " [[ 1.06354768 -1.42632219  1.02163151]\n",
      " [ 0.23156977  1.49535261  0.33251578]\n",
      " [ 0.15972951  0.83533515 -0.40869554]]\n",
      "Target Vector:\n",
      " [1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# creating classification datasets\n",
    "# Generate features matrix and target vector\n",
    "features, target = make_classification(n_samples = 100,\n",
    "                                       n_features = 3,\n",
    "                                       n_informative = 3,\n",
    "                                       n_redundant = 0,\n",
    "                                       n_classes = 2,\n",
    "                                       weights = [.25, .75],\n",
    "                                       random_state = 1)\n",
    "\n",
    "# View feature matrix and target vector\n",
    "print('Feature Matrix:\\n', features[:3])\n",
    "print('Target Vector:\\n', target[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3708b40-9f21-4faa-90c8-ba7b2e72ba6a",
   "metadata": {},
   "source": [
    "if we want a dataset designed to work well with clustering techniques, scikitlearn offers `make_blobs`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa7f18bd-e49c-498e-becb-26e8b6af132d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Matrix:\n",
      " [[ -1.22685609   3.25572052]\n",
      " [ -9.57463218  -4.38310652]\n",
      " [-10.71976941  -4.20558148]]\n",
      "Target Vector:\n",
      " [0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Generate feature matrix and target vector\n",
    "features, target = make_blobs(n_samples = 100,\n",
    "                              n_features = 2,\n",
    "                              centers = 3,\n",
    "                              cluster_std = 0.5,\n",
    "                              shuffle = True,\n",
    "                              random_state = 1)\n",
    "\n",
    "# View feature matrix and target vector\n",
    "print('Feature Matrix:\\n', features[:3])\n",
    "print('Target Vector:\\n', target[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d302d9-45a9-40e1-8905-56c4d0e87c66",
   "metadata": {},
   "source": [
    "In make_regression and make_classification, n_informative determines the\n",
    "number of features that are used to generate the target vector. If n_informative is less\n",
    "than the total number of features (n_features), the resulting dataset will have redun‐\n",
    "dant features that can be identified through feature selection techniques. <br><br>\n",
    "In addition, make_classification contains a weights parameter that allows us to\n",
    "simulate datasets with imbalanced classes. For example, weights = [.25, .75]\n",
    "would return a dataset with 25% of observations belonging to one class and 75% of\n",
    "observations belonging to a second class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba52ce2a-4036-4e48-87c5-6c5a13290bd3",
   "metadata": {},
   "source": [
    "## 3. Data Wrangling\n",
    "Data wrangling is a broad term used, often informally, to describe the process of\n",
    "transforming raw data to a clean and organized format ready for use. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd1bbdc-f209-486f-891f-46632ed32b71",
   "metadata": {},
   "source": [
    "### 3.1 Creating a Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d25fdc72-a16d-4232-ad2f-129709839c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Driver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jacky Jackson</td>\n",
       "      <td>38</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Steven Stevenson</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name  Age  Driver\n",
       "0     Jacky Jackson   38    True\n",
       "1  Steven Stevenson   25   False"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame\n",
    "dataframe = pd.DataFrame()\n",
    "\n",
    "# Add columns\n",
    "dataframe['Name'] = ['Jacky Jackson', 'Steven Stevenson']\n",
    "dataframe['Age'] = [38, 25]\n",
    "dataframe['Driver'] = [True, False]\n",
    "\n",
    "# Show DataFrame\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfc4d64-665b-40bd-b2a6-a1bef8370dff",
   "metadata": {},
   "source": [
    "Alternatively, once we have created a DataFrame object, we can append new rows to\n",
    "the bottom:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a0504246-6974-4520-bee5-02d47329f998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Driver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jacky Jackson</td>\n",
       "      <td>38</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Steven Stevenson</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Molly Mooney</td>\n",
       "      <td>40</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name  Age  Driver\n",
       "0     Jacky Jackson   38    True\n",
       "1  Steven Stevenson   25   False\n",
       "2      Molly Mooney   40    True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create row\n",
    "new_person = pd.Series(['Molly Mooney', 40, True], index=['Name','Age','Driver'])\n",
    "\n",
    "# Append row\n",
    "dataframe.append(new_person, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2cbd5e-b342-497c-b313-b57d2c2e6ca3",
   "metadata": {},
   "source": [
    "### 3.2 Describing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "511d7b73-e1ab-4002-bb87-c9098a0b7c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>1st</td>\n",
       "      <td>29.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>1st</td>\n",
       "      <td>2.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Allison, Mr Hudson Joshua Creighton</td>\n",
       "      <td>1st</td>\n",
       "      <td>30.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Name PClass   Age     Sex  Survived  SexCode\n",
       "0         Allen, Miss Elisabeth Walton    1st  29.0  female         1        1\n",
       "1          Allison, Miss Helen Loraine    1st   2.0  female         0        1\n",
       "2  Allison, Mr Hudson Joshua Creighton    1st  30.0    male         0        0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/chrisalbon/simulated_datasets/master/titanic.csv')\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "94b9ae6f-80ec-4d35-bde8-ae78ab4c0dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1313, 6)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show dimensions\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13997bf4-4ce8-4e83-865e-f1cbac021775",
   "metadata": {},
   "source": [
    "Additionally, we can get descriptive statistics for any numeric columns using\n",
    "describe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d0623ed6-9c93-4b4e-8650-7a11286f3513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>756.000000</td>\n",
       "      <td>1313.000000</td>\n",
       "      <td>1313.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>30.397989</td>\n",
       "      <td>0.342727</td>\n",
       "      <td>0.351866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.259049</td>\n",
       "      <td>0.474802</td>\n",
       "      <td>0.477734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>71.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Age     Survived      SexCode\n",
       "count  756.000000  1313.000000  1313.000000\n",
       "mean    30.397989     0.342727     0.351866\n",
       "std     14.259049     0.474802     0.477734\n",
       "min      0.170000     0.000000     0.000000\n",
       "25%     21.000000     0.000000     0.000000\n",
       "50%     28.000000     0.000000     0.000000\n",
       "75%     39.000000     1.000000     1.000000\n",
       "max     71.000000     1.000000     1.000000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e823b06f-775b-4a1b-8989-267c7b3990d9",
   "metadata": {},
   "source": [
    "### 3.3 Navigating DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "de53838e-b75e-452c-a6b3-b6d07519ebcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name        Allen, Miss Elisabeth Walton\n",
       "PClass                               1st\n",
       "Age                                 29.0\n",
       "Sex                               female\n",
       "Survived                               1\n",
       "SexCode                                1\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select first row\n",
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8a9b495e-ea36-4183-864d-eca7fc76b74e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>1st</td>\n",
       "      <td>2.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Allison, Mr Hudson Joshua Creighton</td>\n",
       "      <td>1st</td>\n",
       "      <td>30.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Allison, Mrs Hudson JC (Bessie Waldo Daniels)</td>\n",
       "      <td>1st</td>\n",
       "      <td>25.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Name PClass   Age     Sex  \\\n",
       "1                    Allison, Miss Helen Loraine    1st   2.0  female   \n",
       "2            Allison, Mr Hudson Joshua Creighton    1st  30.0    male   \n",
       "3  Allison, Mrs Hudson JC (Bessie Waldo Daniels)    1st  25.0  female   \n",
       "\n",
       "   Survived  SexCode  \n",
       "1         0        1  \n",
       "2         0        0  \n",
       "3         0        1  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select three rows\n",
    "df.iloc[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "53460a7c-f188-4584-af69-6ced33f7f76b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>1st</td>\n",
       "      <td>29.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>1st</td>\n",
       "      <td>2.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Allison, Mr Hudson Joshua Creighton</td>\n",
       "      <td>1st</td>\n",
       "      <td>30.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Name PClass   Age     Sex  Survived  SexCode\n",
       "0         Allen, Miss Elisabeth Walton    1st  29.0  female         1        1\n",
       "1          Allison, Miss Helen Loraine    1st   2.0  female         0        1\n",
       "2  Allison, Mr Hudson Joshua Creighton    1st  30.0    male         0        0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select three rows\n",
    "df.iloc[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163409f4-60d3-4408-802f-30c644e39b47",
   "metadata": {},
   "source": [
    "DataFrames do not need to be numerically indexed. We can set the index of a Data‐\n",
    "Frame to any value where the value is unique to each row. For example, we can set the\n",
    "index to be passenger names and then select rows using a name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "69e9889d-830c-4139-b54c-cd1dfa42855c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name        Allen, Miss Elisabeth Walton\n",
       "PClass                               1st\n",
       "Age                                 29.0\n",
       "Sex                               female\n",
       "Survived                               1\n",
       "SexCode                                1\n",
       "Name: Allen, Miss Elisabeth Walton, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set index\n",
    "df = df.set_index(df['Name'])\n",
    "\n",
    "# Show row\n",
    "df.loc['Allen, Miss Elisabeth Walton']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c968f63d-e53d-48a5-b712-b87ed0963e44",
   "metadata": {},
   "source": [
    "* loc is useful when the index of the DataFrame is a label (e.g., a string).\n",
    "* iloc works by looking for the position in the DataFrame. For example, iloc[0]\n",
    "will return the first row regardless of whether the index is an integer or a label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bf75d9-4f68-4d20-bcfb-5150d4a67d1a",
   "metadata": {},
   "source": [
    "### 3.4 Selecting Rows Based on Conditionals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "52f745e2-fe2d-4893-a581-2e818277563e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>1st</td>\n",
       "      <td>29.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>1st</td>\n",
       "      <td>2.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name PClass   Age     Sex  Survived  SexCode\n",
       "0  Allen, Miss Elisabeth Walton    1st  29.0  female         1        1\n",
       "1   Allison, Miss Helen Loraine    1st   2.0  female         0        1"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv('https://raw.githubusercontent.com/chrisalbon/simulated_datasets/master/titanic.csv')\n",
    "\n",
    "# Show top two rows where column 'sex' is 'female'\n",
    "dataframe[dataframe['Sex'] == 'female'].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa8d8bf-b663-45c4-9685-eed4c1586339",
   "metadata": {},
   "source": [
    "Multiple conditions are easy as well. For example, here we select all the rows where\n",
    "the passenger is a female 65 or older:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1c44d203-deba-4a32-a61e-d08782e58c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Crosby, Mrs Edward Gifford (Catherine Elizabet...</td>\n",
       "      <td>1st</td>\n",
       "      <td>69.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Name PClass   Age     Sex  \\\n",
       "73  Crosby, Mrs Edward Gifford (Catherine Elizabet...    1st  69.0  female   \n",
       "\n",
       "    Survived  SexCode  \n",
       "73         1        1  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter rows\n",
    "dataframe[(dataframe['Sex'] == 'female') & (dataframe['Age'] >= 65)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe231af-9e58-41fa-9ef0-71d295acff69",
   "metadata": {},
   "source": [
    "### 3.5 Replacing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "82bd57ef-956d-471a-bb40-bcd54beef24b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Woman\n",
       "1    Woman\n",
       "Name: Sex, dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace values, show two rows\n",
    "dataframe['Sex'].replace(\"female\", \"Woman\").head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9fb36d7f-b5cc-482c-8be6-94bc7cf38c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Woman\n",
       "1    Woman\n",
       "2      Man\n",
       "3    Woman\n",
       "4      Man\n",
       "Name: Sex, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace \"female\" and \"male with \"Woman\" and \"Man\"\n",
    "dataframe['Sex'].replace([\"female\", \"male\"], [\"Woman\", \"Man\"]).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b8bd61-4439-49f8-a6b5-7e2cc1a719d2",
   "metadata": {},
   "source": [
    "replace also accepts regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8bf2a48c-e47f-4169-887c-6df5496ccb58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>First</td>\n",
       "      <td>29.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>First</td>\n",
       "      <td>2.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name PClass   Age     Sex  Survived  SexCode\n",
       "0  Allen, Miss Elisabeth Walton  First  29.0  female         1        1\n",
       "1   Allison, Miss Helen Loraine  First   2.0  female         0        1"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace values, show two rows\n",
    "dataframe.replace(r\"1st\", \"First\", regex=True).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493f44c9-aa7c-4b58-b454-5def3da82bd3",
   "metadata": {},
   "source": [
    "### 3.6 Renaming Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "73f920fd-7201-4c0f-a882-6efab704cc35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Passenger Class</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>1st</td>\n",
       "      <td>29.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>1st</td>\n",
       "      <td>2.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name Passenger Class   Age     Sex  Survived  \\\n",
       "0  Allen, Miss Elisabeth Walton             1st  29.0  female         1   \n",
       "1   Allison, Miss Helen Loraine             1st   2.0  female         0   \n",
       "\n",
       "   SexCode  \n",
       "0        1  \n",
       "1        1  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename column, show two rows\n",
    "dataframe.rename(columns={'PClass': 'Passenger Class'}).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e313492-0053-4ef9-a82e-402ffcd735ad",
   "metadata": {},
   "source": [
    "Notice that the rename method can accept a dictionary as a parameter. We can use the\n",
    "dictionary to change multiple column names at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "36905e35-7f96-44b3-85e0-2944c9706c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Passenger Class</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>1st</td>\n",
       "      <td>29.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>1st</td>\n",
       "      <td>2.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name Passenger Class   Age  Gender  Survived  \\\n",
       "0  Allen, Miss Elisabeth Walton             1st  29.0  female         1   \n",
       "1   Allison, Miss Helen Loraine             1st   2.0  female         0   \n",
       "\n",
       "   SexCode  \n",
       "0        1  \n",
       "1        1  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename columns, show two rows\n",
    "dataframe.rename(columns={'PClass': 'Passenger Class', 'Sex': 'Gender'}).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e446eac-fc18-407b-b0aa-601328fdf9bf",
   "metadata": {},
   "source": [
    "### 3.7 Finding the Minimum, Maximum, Sum, Average, and Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8819bdcd-6a34-4a61-9e1f-b3859f9dd2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum\t: 71.0\n",
      "Minimum\t: 0.17\n",
      "Mean\t: 30.397989417989415\n",
      "Sum\t: 22980.88\n",
      "Count\t: 756\n"
     ]
    }
   ],
   "source": [
    "# Calculate statistics\n",
    "print('Maximum\\t:', dataframe['Age'].max())\n",
    "print('Minimum\\t:', dataframe['Age'].min())\n",
    "print('Mean\\t:', dataframe['Age'].mean())\n",
    "print('Sum\\t:', dataframe['Age'].sum())\n",
    "print('Count\\t:', dataframe['Age'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2a73b7-7ae8-484f-b842-60413e565477",
   "metadata": {},
   "source": [
    "### 3.8 Finding Unique Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "73ab5e9a-7f95-40e0-98d9-94ffe631081a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['female', 'male'], dtype=object)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select unique values\n",
    "dataframe['Sex'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6721dd-d8ab-461f-baa0-6594bbd5711d",
   "metadata": {},
   "source": [
    "Alternatively, `value_counts` will display all unique values with the number of times\n",
    "each value appears:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "29ed2425-3ebc-4406-8315-6f2c5cab59ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      851\n",
       "female    462\n",
       "Name: Sex, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show counts\n",
    "dataframe['Sex'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5387dc2-7d51-43fe-bd4f-99a1483e6ecd",
   "metadata": {},
   "source": [
    "### 3.9 Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0b8366da-11a4-44fb-a06a-ffe17e511816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Aubert, Mrs Leontine Pauline</td>\n",
       "      <td>1st</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Barkworth, Mr Algernon H</td>\n",
       "      <td>1st</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Baumann, Mr John D</td>\n",
       "      <td>1st</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Name PClass  Age     Sex  Survived  SexCode\n",
       "12  Aubert, Mrs Leontine Pauline    1st  NaN  female         1        1\n",
       "13      Barkworth, Mr Algernon H    1st  NaN    male         1        0\n",
       "14            Baumann, Mr John D    1st  NaN    male         0        0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Select missing values, show two rows\n",
    "dataframe[dataframe['Age'].isnull()].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "31c31143-94d0-423a-a1d9-676d4b614bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name        False\n",
       "PClass      False\n",
       "Age          True\n",
       "Sex         False\n",
       "Survived    False\n",
       "SexCode     False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# melihat columns with missing value\n",
    "dataframe.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaa74b1-389f-4dda-883f-527922565186",
   "metadata": {},
   "source": [
    "Oftentimes a dataset uses a specific value to denote a missing observation, such as\n",
    "NONE, -999, or .. pandas’ `read_csv` includes a parameter allowing us to specify the\n",
    "values used to indicate missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0cf21733-df44-46db-9383-595a5d347d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Aubert, Mrs Leontine Pauline</td>\n",
       "      <td>1st</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Barkworth, Mr Algernon H</td>\n",
       "      <td>1st</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Baumann, Mr John D</td>\n",
       "      <td>1st</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Name PClass  Age     Sex  Survived  SexCode\n",
       "12  Aubert, Mrs Leontine Pauline    1st  NaN  female         1        1\n",
       "13      Barkworth, Mr Algernon H    1st  NaN    male         1        0\n",
       "14            Baumann, Mr John D    1st  NaN    male         0        0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data, set missing values\n",
    "url = 'https://raw.githubusercontent.com/chrisalbon/simulated_datasets/master/titanic.csv'\n",
    "dataframe = pd.read_csv(url, na_values=[np.nan, 'NONE', -999])\n",
    "\n",
    "dataframe[dataframe['Age'].isnull()].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1dbd5b-e0be-4d47-a3ca-18bbae2530c2",
   "metadata": {},
   "source": [
    "### 3.10 Deleting a Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7bb75f13-cd7c-4ab7-a5f7-de98f9acf495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>1st</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>1st</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name PClass     Sex  Survived  SexCode\n",
       "0  Allen, Miss Elisabeth Walton    1st  female         1        1\n",
       "1   Allison, Miss Helen Loraine    1st  female         0        1"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv(url)\n",
    "\n",
    "# Delete column\n",
    "dataframe.drop('Age', axis=1).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a729bc46-7824-41f0-8d9f-f2341616a30e",
   "metadata": {},
   "source": [
    "You can also use a list of column names as the main argument to drop multiple columns at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ae4967e6-8c5c-4f5d-b91c-9ce1613d160c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>1st</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name PClass  Survived  SexCode\n",
       "0  Allen, Miss Elisabeth Walton    1st         1        1\n",
       "1   Allison, Miss Helen Loraine    1st         0        1"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop columns\n",
    "dataframe.drop(['Age', 'Sex'], axis=1).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d9de53-5b53-4ae2-bbf2-5c0917358ef9",
   "metadata": {},
   "source": [
    "If a column does not have a name (which can sometimes happen), you can drop it by\n",
    "its column index using `dataframe.columns`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ca28aca1-7f78-49a1-8c17-e7f8280baafa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PClass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1st</td>\n",
       "      <td>29.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1st</td>\n",
       "      <td>2.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PClass   Age     Sex  Survived  SexCode\n",
       "0    1st  29.0  female         1        1\n",
       "1    1st   2.0  female         0        1"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop column\n",
    "dataframe.drop(dataframe.columns[0], axis=1).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf7c540-164d-452b-89b4-9cc7440d0294",
   "metadata": {},
   "source": [
    "### 3.11 Deleting a Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "dce8bd7c-9e48-49ab-99f9-c356c3afcc5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>Yasbeck, Mrs Antoni</td>\n",
       "      <td>3rd</td>\n",
       "      <td>15.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>Zabour, Miss Hileni</td>\n",
       "      <td>3rd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>Zabour, Miss Tamini</td>\n",
       "      <td>3rd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Name PClass   Age     Sex  Survived  SexCode\n",
       "1304  Yasbeck, Mrs Antoni    3rd  15.0  female         1        1\n",
       "1306  Zabour, Miss Hileni    3rd   NaN  female         0        1\n",
       "1307  Zabour, Miss Tamini    3rd   NaN  female         0        1"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete rows, show first two rows of output\n",
    "dataframe[dataframe['Sex'] != 'male'].tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10605549-d426-4bfc-8f23-f4da6332ecc5",
   "metadata": {},
   "source": [
    "While technically you can use the drop method (for example, df.drop([0, 1],\n",
    "axis=0) to drop the first two rows), a more practical method is simply to wrap a\n",
    "boolean condition inside df[]. The reason is because we can use the power of conditionals to delete either a single row or (far more likely) many rows at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fcd17d05-8434-4e82-9062-5f7e1b1e49a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>1st</td>\n",
       "      <td>29.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Allison, Mr Hudson Joshua Creighton</td>\n",
       "      <td>1st</td>\n",
       "      <td>30.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Name PClass   Age     Sex  Survived  SexCode\n",
       "0         Allen, Miss Elisabeth Walton    1st  29.0  female         1        1\n",
       "2  Allison, Mr Hudson Joshua Creighton    1st  30.0    male         0        0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete row, show first two rows of output\n",
    "dataframe[dataframe['Name'] != 'Allison, Miss Helen Loraine'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c4fc60cf-17c9-480e-bdd8-76f17860361d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>1st</td>\n",
       "      <td>2.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Allison, Mr Hudson Joshua Creighton</td>\n",
       "      <td>1st</td>\n",
       "      <td>30.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Name PClass   Age     Sex  Survived  SexCode\n",
       "1          Allison, Miss Helen Loraine    1st   2.0  female         0        1\n",
       "2  Allison, Mr Hudson Joshua Creighton    1st  30.0    male         0        0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete row, show first two rows of output\n",
    "dataframe[dataframe.index != 0].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11eecede-990d-444c-8e5d-9444ca4d4ad6",
   "metadata": {},
   "source": [
    "### 3.12 Dropping Duplicate Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "91b5d1f0-dcaa-41c4-ac43-2225bf25243b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>1st</td>\n",
       "      <td>29.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>1st</td>\n",
       "      <td>2.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name PClass   Age     Sex  Survived  SexCode\n",
       "0  Allen, Miss Elisabeth Walton    1st  29.0  female         1        1\n",
       "1   Allison, Miss Helen Loraine    1st   2.0  female         0        1"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop duplicates, show first two rows of output\n",
    "dataframe.drop_duplicates().head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65439811-26b4-4ddc-ae44-7a546fa64906",
   "metadata": {},
   "source": [
    "A keen reader will notice that the solution didn’t actually drop any rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "eb60d716-32b6-4295-a195-45cc3ad9c66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Of Rows In The Original DataFrame: 1313\n",
      "Number Of Rows After Deduping: 1313\n"
     ]
    }
   ],
   "source": [
    "# Show number of rows\n",
    "print(\"Number Of Rows In The Original DataFrame:\", len(dataframe))\n",
    "print(\"Number Of Rows After Deduping:\", len(dataframe.drop_duplicates()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dbbb64-60b2-410e-a6d2-52ebd417aaa5",
   "metadata": {},
   "source": [
    "The reason is because `drop_duplicates` defaults to only dropping rows that match\n",
    "perfectly across all columns. Under this condition, every row in our DataFrame, data\n",
    "frame, is actually unique. However, often we want to consider only a subset of columns to check for duplicate rows. We can accomplish this using the subset parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a231638f-982c-4495-aab0-799720836dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>1st</td>\n",
       "      <td>29.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Allison, Mr Hudson Joshua Creighton</td>\n",
       "      <td>1st</td>\n",
       "      <td>30.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Name PClass   Age     Sex  Survived  SexCode\n",
       "0         Allen, Miss Elisabeth Walton    1st  29.0  female         1        1\n",
       "2  Allison, Mr Hudson Joshua Creighton    1st  30.0    male         0        0"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop duplicates\n",
    "dataframe.drop_duplicates(subset=['Sex'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82131526-acb7-4a77-9151-8d745145d3f9",
   "metadata": {},
   "source": [
    "Take a close look at the preceding output: we told drop_duplicates to only consider\n",
    "any two rows with the same value for Sex to be duplicates and to drop them. Now we\n",
    "are left with a DataFrame of only two rows: one man and one woman. You might be\n",
    "asking why drop_duplicates decided to keep these two rows instead of two different\n",
    "rows. The answer is that drop_duplicates defaults to keeping the first occurrence of\n",
    "a duplicated row and dropping the rest. We can control this behavior using the keep\n",
    "parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a59ee353-f4ec-4788-8200-dfc772a10087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>Zabour, Miss Tamini</td>\n",
       "      <td>3rd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>Zimmerman, Leo</td>\n",
       "      <td>3rd</td>\n",
       "      <td>29.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Name PClass   Age     Sex  Survived  SexCode\n",
       "1307  Zabour, Miss Tamini    3rd   NaN  female         0        1\n",
       "1312       Zimmerman, Leo    3rd  29.0    male         0        0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop duplicates\n",
    "dataframe.drop_duplicates(subset=['Sex'], keep='last')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10c62e7-c2bd-4599-b8c0-c77cbe7cf44e",
   "metadata": {},
   "source": [
    "### 3.13 Grouping Rows by Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b4dbc4f7-9a91-4229-9486-efaaf4116b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>29.396424</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>31.014338</td>\n",
       "      <td>0.166863</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Age  Survived  SexCode\n",
       "Sex                                 \n",
       "female  29.396424  0.666667      1.0\n",
       "male    31.014338  0.166863      0.0"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group rows by the values of the column 'Sex', calculate mean\n",
    "# of each group\n",
    "dataframe.groupby('Sex').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2b3125-b4b6-490e-9e58-1b40d92e9aff",
   "metadata": {},
   "source": [
    "When talking about grouping we often\n",
    "use shorthand and say “group by gender,” but that is incomplete. For grouping to be useful, we need to group by something and then apply a function to each of those\n",
    "groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "90c3efbf-77fa-4a71-a399-5bfac87cf458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived\n",
       "0    863\n",
       "1    450\n",
       "Name: Name, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group rows, count rows\n",
    "dataframe.groupby('Survived')['Name'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e06400-b2bf-4370-9ff6-47b96b839a34",
   "metadata": {},
   "source": [
    "*In this case we group the data into survived or not, then count the number of names (i.e.,\n",
    "passengers) in each group.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ac642a8f-00ee-4822-8476-824172f1c930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SexCode\n",
       "0    851\n",
       "1    462\n",
       "Name: Name, dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.groupby('SexCode')['Name'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef15f33-0cee-4036-af01-afbdeb57724d",
   "metadata": {},
   "source": [
    "### 3.14 Grouping Rows by Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b38d4caa-5ebf-4f7d-b637-e65a563d1df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sale_Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-06-06 00:00:00</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-06 00:00:30</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-06 00:01:00</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-06 00:01:30</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-06 00:02:00</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Sale_Amount\n",
       "2017-06-06 00:00:00            3\n",
       "2017-06-06 00:00:30            1\n",
       "2017-06-06 00:01:00            2\n",
       "2017-06-06 00:01:30            4\n",
       "2017-06-06 00:02:00            9"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create date range\n",
    "time_index = pd.date_range('06/06/2017', periods=100000, freq='30S')\n",
    "\n",
    "# Create DataFrame\n",
    "dataframe = pd.DataFrame(index=time_index)\n",
    "\n",
    "# Create column of random values\n",
    "dataframe['Sale_Amount'] = np.random.randint(1, 10, 100000)\n",
    "\n",
    "# show dataframe\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "657cf09a-c317-4d24-9a36-d8cf734ca243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sale_Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-06-11</th>\n",
       "      <td>86297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-18</th>\n",
       "      <td>101097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-25</th>\n",
       "      <td>100959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-02</th>\n",
       "      <td>100708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-09</th>\n",
       "      <td>100414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-16</th>\n",
       "      <td>10450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Sale_Amount\n",
       "2017-06-11        86297\n",
       "2017-06-18       101097\n",
       "2017-06-25       100959\n",
       "2017-07-02       100708\n",
       "2017-07-09       100414\n",
       "2017-07-16        10450"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group rows by week, calculate sum per week\n",
    "dataframe.resample('W').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9073d087-a99c-48c3-9d4f-c333934b849a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sale_Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-06-11</th>\n",
       "      <td>4.994039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-25</th>\n",
       "      <td>5.011310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-09</th>\n",
       "      <td>4.988145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-23</th>\n",
       "      <td>5.024038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Sale_Amount\n",
       "2017-06-11     4.994039\n",
       "2017-06-25     5.011310\n",
       "2017-07-09     4.988145\n",
       "2017-07-23     5.024038"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by two weeks, calculate mean\n",
    "dataframe.resample('2W').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ac697121-01a5-4a13-babf-dd7dc8c5269e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sale_Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-06-30</th>\n",
       "      <td>72000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-31</th>\n",
       "      <td>28000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Sale_Amount\n",
       "2017-06-30        72000\n",
       "2017-07-31        28000"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by month, count rows\n",
    "dataframe.resample('M').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168d6874-a30f-49d0-aee8-421fee47306a",
   "metadata": {},
   "source": [
    "### 3.15 Looping Over a Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4a70ad1e-0422-428c-8eea-585cc7f9dc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALLEN, MISS ELISABETH WALTON\n",
      "ALLISON, MISS HELEN LORAINE\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "dataframe = pd.read_csv(url)\n",
    "\n",
    "# Print first two names uppercased\n",
    "for name in dataframe['Name'][0:2]:\n",
    "     print(name.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e77ac6f2-2323-4030-b53e-aafce467f38d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ALLEN, MISS ELISABETH WALTON', 'ALLISON, MISS HELEN LORAINE']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using list comprehension\n",
    "[name.upper() for name in dataframe['Name'][0:2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc100fc-fcd9-4742-b6fc-ec3b8094b345",
   "metadata": {},
   "source": [
    "### 3.16 Applying a Function Over All Elements in a Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d8785116-5b42-4fb1-b95c-4be9f87ad1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function\n",
    "uppercase = lambda x: x.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7afe6d1d-f0e0-4d7c-a5a5-b9d80beb4206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ALLEN, MISS ELISABETH WALTON\n",
       "1     ALLISON, MISS HELEN LORAINE\n",
       "Name: Name, dtype: object"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply function, show two rows\n",
    "dataframe['Name'].apply(uppercase)[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18130e55-d83f-4384-a7d2-71755fe65715",
   "metadata": {},
   "source": [
    "### 3.17 Applying a Function to Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2b60dcc3-f2e4-4ddb-af21-d412abe4d888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>462</td>\n",
       "      <td>462</td>\n",
       "      <td>288</td>\n",
       "      <td>462</td>\n",
       "      <td>462</td>\n",
       "      <td>462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>851</td>\n",
       "      <td>851</td>\n",
       "      <td>468</td>\n",
       "      <td>851</td>\n",
       "      <td>851</td>\n",
       "      <td>851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name  PClass  Age  Sex  Survived  SexCode\n",
       "Sex                                              \n",
       "female   462     462  288  462       462      462\n",
       "male     851     851  468  851       851      851"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group rows, apply function to groups\n",
    "dataframe.groupby('Sex').apply(lambda x: x.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c524e971-d093-46a5-9dc2-bbce9c2d3f08",
   "metadata": {},
   "source": [
    "### 3.18 Concatenating DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "bca8e508-4058-44b3-bfb1-8959e38e4e13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alex</td>\n",
       "      <td>Anderson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Amy</td>\n",
       "      <td>Ackerman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Allen</td>\n",
       "      <td>Ali</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Billy</td>\n",
       "      <td>Bonder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Brian</td>\n",
       "      <td>Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>Bran</td>\n",
       "      <td>Balwner</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id  first      last\n",
       "0  1   Alex  Anderson\n",
       "1  2    Amy  Ackerman\n",
       "2  3  Allen       Ali\n",
       "0  4  Billy    Bonder\n",
       "1  5  Brian     Black\n",
       "2  6   Bran   Balwner"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Dataframe\n",
    "data_a = {'id': ['1', '2', '3'],\n",
    "         'first': ['Alex', 'Amy', 'Allen'],\n",
    "         'last': ['Anderson', 'Ackerman', 'Ali']}\n",
    "dataframe_a = pd.DataFrame(data_a, columns = ['id', 'first', 'last'])\n",
    "\n",
    "# Create DataFrame\n",
    "data_b = {'id': ['4', '5', '6'],\n",
    "         'first': ['Billy', 'Brian', 'Bran'],\n",
    "         'last': ['Bonder', 'Black', 'Balwner']}\n",
    "dataframe_b = pd.DataFrame(data_b, columns = ['id', 'first', 'last'])\n",
    "\n",
    "# Concatenate DataFrames by rows\n",
    "pd.concat([dataframe_a, dataframe_b], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "714aa517-f550-40b9-a9c8-0140b7087d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>id</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alex</td>\n",
       "      <td>Anderson</td>\n",
       "      <td>4</td>\n",
       "      <td>Billy</td>\n",
       "      <td>Bonder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Amy</td>\n",
       "      <td>Ackerman</td>\n",
       "      <td>5</td>\n",
       "      <td>Brian</td>\n",
       "      <td>Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Allen</td>\n",
       "      <td>Ali</td>\n",
       "      <td>6</td>\n",
       "      <td>Bran</td>\n",
       "      <td>Balwner</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id  first      last id  first     last\n",
       "0  1   Alex  Anderson  4  Billy   Bonder\n",
       "1  2    Amy  Ackerman  5  Brian    Black\n",
       "2  3  Allen       Ali  6   Bran  Balwner"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate DataFrames by columns\n",
    "pd.concat([dataframe_a, dataframe_b], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee0b1a1-28da-47f3-9b53-5e85ce17be4f",
   "metadata": {},
   "source": [
    "Alternatively we can use append to add a new row to a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "fd6721ff-ac7d-4846-aaf6-91389f766775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alex</td>\n",
       "      <td>Anderson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Amy</td>\n",
       "      <td>Ackerman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Allen</td>\n",
       "      <td>Ali</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>Chris</td>\n",
       "      <td>Chillon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  first      last\n",
       "0   1   Alex  Anderson\n",
       "1   2    Amy  Ackerman\n",
       "2   3  Allen       Ali\n",
       "3  10  Chris   Chillon"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create row\n",
    "row = pd.Series([10, 'Chris', 'Chillon'], index=['id', 'first', 'last'])\n",
    "\n",
    "# Append row\n",
    "dataframe_a.append(row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9109550-5d54-4409-b210-7a40ae748c9c",
   "metadata": {},
   "source": [
    "### 3.19 Merging DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3a0b5d4d-57b0-477a-aca4-c4bac10dcf68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>name</th>\n",
       "      <th>total_sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Alice Bees</td>\n",
       "      <td>23456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Tim Horton</td>\n",
       "      <td>2512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  employee_id        name  total_sales\n",
       "0           3  Alice Bees        23456\n",
       "1           4  Tim Horton         2512"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame\n",
    "employee_data = {'employee_id': ['1', '2', '3', '4'],\n",
    "                 'name': ['Amy Jones', 'Allen Keys', 'Alice Bees',\n",
    "                 'Tim Horton']}\n",
    "dataframe_employees = pd.DataFrame(employee_data, columns = ['employee_id','name'])\n",
    "\n",
    "# Create DataFrame\n",
    "sales_data = {'employee_id': ['3', '4', '5', '6'],\n",
    "              'total_sales': [23456, 2512, 2345, 1455]}\n",
    "dataframe_sales = pd.DataFrame(sales_data, columns = ['employee_id','total_sales'])\n",
    "\n",
    "# Merge DataFrames\n",
    "pd.merge(dataframe_employees, dataframe_sales, on='employee_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a16dce1-af15-497b-96a9-34defb9f0588",
   "metadata": {},
   "source": [
    "merge defaults to inner joins. If we want to do an outer join, we can specify that with\n",
    "the how parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e0b29187-8d25-4511-a954-49a9197dcd40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>name</th>\n",
       "      <th>total_sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Amy Jones</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Allen Keys</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Alice Bees</td>\n",
       "      <td>23456.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Tim Horton</td>\n",
       "      <td>2512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2345.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1455.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  employee_id        name  total_sales\n",
       "0           1   Amy Jones          NaN\n",
       "1           2  Allen Keys          NaN\n",
       "2           3  Alice Bees      23456.0\n",
       "3           4  Tim Horton       2512.0\n",
       "4           5         NaN       2345.0\n",
       "5           6         NaN       1455.0"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge DataFrames\n",
    "pd.merge(dataframe_employees, dataframe_sales, on='employee_id', how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ea5120-358f-4105-bd65-9be36fe97e11",
   "metadata": {},
   "source": [
    "The same parameter can be used to specify left and right joins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "37ad2627-e518-480a-b9d5-6697ff2f2e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>name</th>\n",
       "      <th>total_sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Amy Jones</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Allen Keys</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Alice Bees</td>\n",
       "      <td>23456.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Tim Horton</td>\n",
       "      <td>2512.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  employee_id        name  total_sales\n",
       "0           1   Amy Jones          NaN\n",
       "1           2  Allen Keys          NaN\n",
       "2           3  Alice Bees      23456.0\n",
       "3           4  Tim Horton       2512.0"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge DataFrames\n",
    "pd.merge(dataframe_employees, dataframe_sales, on='employee_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbd0742-6a6f-4de8-a6cd-d0f3188adf85",
   "metadata": {},
   "source": [
    "We can also specify the column name in each DataFrame to merge on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "93209b8b-6986-4796-927e-d61a92dbfcd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>name</th>\n",
       "      <th>total_sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Alice Bees</td>\n",
       "      <td>23456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Tim Horton</td>\n",
       "      <td>2512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  employee_id        name  total_sales\n",
       "0           3  Alice Bees        23456\n",
       "1           4  Tim Horton         2512"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge DataFrames\n",
    "pd.merge(dataframe_employees,\n",
    "         dataframe_sales,\n",
    "         left_on='employee_id',\n",
    "         right_on='employee_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8321b7-d306-4d05-badc-7df09b566cf1",
   "metadata": {},
   "source": [
    "## 4. Handling Numerical Data\n",
    "Quantitative data is the measurement of something—whether class size, monthly\n",
    "sales, or student scores. The natural way to represent these quantities is numerically\n",
    "(e.g., 29 students, $529,392 in sales). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b6eff0-79a8-43fb-a016-8ee21268842e",
   "metadata": {},
   "source": [
    "### 4.1 Rescaling a Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e5b531d8-cf56-409e-8e52-24f2b81ca55f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [0.28571429],\n",
       "       [0.35714286],\n",
       "       [0.42857143],\n",
       "       [1.        ]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create feature\n",
    "feature = np.array([[-500.5],\n",
    "                    [-100.1],\n",
    "                    [0],\n",
    "                    [100.1],\n",
    "                    [900.9]])\n",
    "\n",
    "# Create scaler\n",
    "minmax_scale = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Scale feature\n",
    "scaled_feature = minmax_scale.fit_transform(feature)\n",
    "\n",
    "# Show feature\n",
    "scaled_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda381ef-4688-4662-adb2-f0b402279f57",
   "metadata": {},
   "source": [
    "<img src='minmax.png'>\n",
    "where x is the feature vector, x’i\n",
    " is an individual element of feature x, and x’i\n",
    " is the\n",
    "rescaled element. In our example, we can see from the outputted array that the fea‐\n",
    "ture has been successfully rescaled to between 0 and 1:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e52604-eb71-49e9-b6e9-68afc6d90d88",
   "metadata": {},
   "source": [
    "### 4.2 Standardizing a Feature\n",
    "You want to transform a feature to have a mean of 0 and a standard deviation of 1 (using z-score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3da93ea6-2301-4541-a9be-c4f628095c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.76058269],\n",
       "       [-0.54177196],\n",
       "       [-0.35009716],\n",
       "       [-0.32271504],\n",
       "       [ 1.97516685]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create feature\n",
    "x = np.array([[-1000.1],\n",
    "              [-200.2],\n",
    "              [500.5],\n",
    "              [600.6],\n",
    "              [9000.9]])\n",
    "\n",
    "# Create scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Transform the feature\n",
    "standardized = scaler.fit_transform(x)\n",
    "\n",
    "# Show feature\n",
    "standardized "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89dc7d9-ed3b-4c78-8dee-20e719287dce",
   "metadata": {},
   "source": [
    "<img src='standard.png'>\n",
    "where x’i\n",
    " is our standardized form of xi\n",
    ". The transformed feature represents the num‐\n",
    "ber of standard deviations the original value is away from the feature’s mean value\n",
    "(also called a z-score in statistics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6c42b538-ed0b-41a3-b0b2-e8c965098e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0\n",
      "Standard deviation: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Print mean and standard deviation\n",
    "print(\"Mean:\", round(standardized.mean()))\n",
    "print(\"Standard deviation:\", standardized.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5907db03-905f-46f9-9181-582398d98cab",
   "metadata": {},
   "source": [
    "If our data has significant outliers, it can negatively impact our standardization by\n",
    "affecting the feature’s mean and variance. In this scenario, it is often helpful to instead\n",
    "rescale the feature using the median and quartile range. In scikit-learn, we do this\n",
    "using the RobustScaler method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1c017199-75d8-4a70-ae1a-193fef37e4b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.87387612],\n",
       "       [-0.875     ],\n",
       "       [ 0.        ],\n",
       "       [ 0.125     ],\n",
       "       [10.61488511]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create scaler\n",
    "robust_scaler = RobustScaler()\n",
    "\n",
    "# Transform feature\n",
    "robust_scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0872c9-13b7-4a2e-855b-604dd0d619d0",
   "metadata": {},
   "source": [
    "### 4.3 Normalizing Observations\n",
    "rescale the feature values of observations to have unit norm (a total\n",
    "length of 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "39067c7d-a3ff-4ee5-823b-eb19b606bbe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.70710678, 0.70710678],\n",
       "       [0.30782029, 0.95144452],\n",
       "       [0.07405353, 0.99725427],\n",
       "       [0.04733062, 0.99887928],\n",
       "       [0.95709822, 0.28976368]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create feature matrix\n",
    "features = np.array([[0.5, 0.5],\n",
    "                     [1.1, 3.4],\n",
    "                     [1.5, 20.2],\n",
    "                     [1.63, 34.4],\n",
    "                     [10.9, 3.3]])\n",
    "\n",
    "# Create normalizer\n",
    "normalizer = Normalizer(norm=\"l2\")\n",
    "\n",
    "# Transform feature matrix\n",
    "normalizer.transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6b31df-ffa3-4192-9667-c2d25a352ecd",
   "metadata": {},
   "source": [
    "<img src='l2.png'>\n",
    "where x is an individual observation and xn is that observation’s value for the nth feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "45fd108a-7182-4a24-8153-47027bea2024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.70710678, 0.70710678],\n",
       "       [0.30782029, 0.95144452],\n",
       "       [0.07405353, 0.99725427],\n",
       "       [0.04733062, 0.99887928],\n",
       "       [0.95709822, 0.28976368]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform feature matrix\n",
    "features_l2_norm = Normalizer(norm=\"l2\").transform(features)\n",
    "\n",
    "# Show feature matrix\n",
    "features_l2_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56e1071-8a1e-43e8-8d48-e4058ea49982",
   "metadata": {},
   "source": [
    " Manhattan norm (L1)\n",
    "<img src='l1.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8d8ca6dd-7142-446c-b67f-69148a49282e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.5       ],\n",
       "       [0.24444444, 0.75555556],\n",
       "       [0.06912442, 0.93087558],\n",
       "       [0.04524008, 0.95475992],\n",
       "       [0.76760563, 0.23239437]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform feature matrix\n",
    "features_l1_norm = Normalizer(norm=\"l1\").transform(features)\n",
    "\n",
    "# Show feature matrix\n",
    "features_l1_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb0a801-89dd-4a9a-b4ee-0fec838b31ec",
   "metadata": {},
   "source": [
    "Intuitively, L2 norm can be thought of as the distance between two points in New\n",
    "York for a bird (i.e., a straight line), while L1 can be thought of as the distance for a\n",
    "human walking on the street (walk north one block, east one block, north one block,\n",
    "east one block, etc.), which is why it is called “Manhattan norm” or “Taxicab norm.”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7aecef-ed9f-42cd-a16e-9ae27a0f3994",
   "metadata": {},
   "source": [
    "### 4.4 Generating Polynomial and Interaction Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c9b06c33-37a3-4a35-b144-a55ce4595c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 3., 4., 6., 9.],\n",
       "       [2., 3., 4., 6., 9.],\n",
       "       [2., 3., 4., 6., 9.]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create feature matrix\n",
    "features = np.array([[2, 3],\n",
    "                     [2, 3],\n",
    "                     [2, 3]])\n",
    "\n",
    "# Create PolynomialFeatures object\n",
    "polynomial_interaction = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "# Create polynomial features\n",
    "polynomial_interaction.fit_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7240adb-157e-43c4-a5f6-34fcc34f782a",
   "metadata": {},
   "source": [
    "### 4.5 Transforming Features\n",
    " want to make a custom transformation to one or more features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e794db75-ecde-4a72-b57d-167e861ba834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12, 13],\n",
       "       [12, 13],\n",
       "       [12, 13]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create feature matrix\n",
    "features = np.array([[2, 3],\n",
    "                     [2, 3],\n",
    "                     [2, 3]])\n",
    "\n",
    "# define simple function\n",
    "add_ten = lambda x: x + 10\n",
    "\n",
    "# Create transformer\n",
    "ten_transformer = FunctionTransformer(add_ten)\n",
    "\n",
    "# Transform feature matrix\n",
    "ten_transformer.transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13629557-1450-47dc-b486-2da746127968",
   "metadata": {},
   "source": [
    "### 4.6 Detecting Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "177efdb6-98ea-44e4-aed1-0433f82b8dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1,  1,  1,  1,  1,  1,  1,  1,  1])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create simulated data\n",
    "features, _ = make_blobs(n_samples = 10,\n",
    "                         n_features = 2,\n",
    "                         centers = 1,\n",
    "                         random_state = 1)\n",
    "\n",
    "# Replace the first observation's values with extreme values\n",
    "features[0,0] = 10000\n",
    "features[0,1] = 10000\n",
    "outlier_detector = EllipticEnvelope(contamination=.1)\n",
    "\n",
    "# Fit detector\n",
    "outlier_detector.fit(features)\n",
    "\n",
    "# Predict outliers\n",
    "outlier_detector.predict(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971b1e6b-5f0a-4d8f-9f22-69e29a41fe21",
   "metadata": {},
   "source": [
    "1 is inlier and -1 is outlier<br><br>\n",
    "Instead of looking at observations as a whole, we can instead look at individual features and identify extreme values in those features using interquartile range (IQR):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "d2a9fffa-3166-413c-a62f-6e2e73d3504c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0], dtype=int64),)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create one feature\n",
    "feature = features[:,0]\n",
    "\n",
    "# Create a function to return index of outliers\n",
    "def indicies_of_outliers(x):\n",
    "    q1, q3 = np.percentile(x, [25, 75])\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - (iqr * 1.5)\n",
    "    upper_bound = q3 + (iqr * 1.5)\n",
    "    return np.where((x > upper_bound) | (x < lower_bound))\n",
    "\n",
    "# Run function\n",
    "indicies_of_outliers(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840e2c6f-c4aa-4708-b4f9-231faa2bdff6",
   "metadata": {},
   "source": [
    "Outliers are commonly defined as any value 1.5\n",
    "IQRs less than the first quartile or 1.5 IQRs greater than the third quartile."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b883a2bd-c68f-4f5c-ada2-1f58c8a48da1",
   "metadata": {},
   "source": [
    "### 4.7 Handling Outliers\n",
    "Typically we have three strategies we can use to handle outliers. First, we can drop\n",
    "them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "bdd6be10-96f2-4891-b488-381a0df7a6e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>Square_Feet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>534433</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>392333</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>293222</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Price  Bathrooms  Square_Feet\n",
       "0  534433        2.0         1500\n",
       "1  392333        3.5         2500\n",
       "2  293222        2.0         1500"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame\n",
    "houses = pd.DataFrame()\n",
    "houses['Price'] = [534433, 392333, 293222, 4322032]\n",
    "houses['Bathrooms'] = [2, 3.5, 2, 116]\n",
    "houses['Square_Feet'] = [1500, 2500, 1500, 48000]\n",
    "\n",
    "# Filter observations\n",
    "houses[houses['Bathrooms'] < 20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab86eefd-4d6a-4b26-af67-fa1963d8868c",
   "metadata": {},
   "source": [
    "Second, we can mark them as outliers and include it as a feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e06d9751-c105-4a71-9b0b-41c7209da5de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>Square_Feet</th>\n",
       "      <th>Outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>534433</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>392333</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>293222</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4322032</td>\n",
       "      <td>116.0</td>\n",
       "      <td>48000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Price  Bathrooms  Square_Feet  Outlier\n",
       "0   534433        2.0         1500        0\n",
       "1   392333        3.5         2500        0\n",
       "2   293222        2.0         1500        0\n",
       "3  4322032      116.0        48000        1"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create feature based on boolean condition\n",
    "houses[\"Outlier\"] = np.where(houses[\"Bathrooms\"] < 20, 0, 1)\n",
    "\n",
    "# Show data\n",
    "houses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aea0488-f6a6-4248-ad1f-c1837327d38a",
   "metadata": {},
   "source": [
    "Finally, we can transform the feature to dampen the effect of the outlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e87d3591-9f27-45b8-9ecd-9e74c45b817d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>Square_Feet</th>\n",
       "      <th>Outlier</th>\n",
       "      <th>Log_Of_Square_Feet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>534433</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "      <td>7.313220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>392333</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "      <td>7.824046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>293222</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "      <td>7.313220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4322032</td>\n",
       "      <td>116.0</td>\n",
       "      <td>48000</td>\n",
       "      <td>1</td>\n",
       "      <td>10.778956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Price  Bathrooms  Square_Feet  Outlier  Log_Of_Square_Feet\n",
       "0   534433        2.0         1500        0            7.313220\n",
       "1   392333        3.5         2500        0            7.824046\n",
       "2   293222        2.0         1500        0            7.313220\n",
       "3  4322032      116.0        48000        1           10.778956"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log feature\n",
    "houses[\"Log_Of_Square_Feet\"] = [np.log(x) for x in houses[\"Square_Feet\"]]\n",
    "\n",
    "# Show data\n",
    "houses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20e9a9f-4379-460b-918e-bbffe678678e",
   "metadata": {},
   "source": [
    "### 4.8 Discretizating Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "76da5dcb-24b8-42b5-93d5-e4fcef276dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create feature\n",
    "age = np.array([[6],\n",
    "               [12],\n",
    "               [19],\n",
    "               [36],\n",
    "               [65],\n",
    "               [18]])\n",
    "\n",
    "# Create binarizer\n",
    "binarizer = Binarizer(threshold=18) # 0 = <18\n",
    "\n",
    "# Transform feature\n",
    "binarizer.fit_transform(age)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d443a2-bbf5-489c-8415-fa3edd09e45f",
   "metadata": {},
   "source": [
    "Second, we can break up numerical features according to multiple thresholds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "d60205e6-69ce-4036-a9f8-7a8492454b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [2],\n",
       "       [3],\n",
       "       [0]], dtype=int64)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bin feature\n",
    "np.digitize(age, bins=[20,30,64])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9525676e-9f49-4dae-8860-4c061f7e1f47",
   "metadata": {},
   "source": [
    "### 4.9 Grouping Observations Using Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "b09ae3ee-1586-49d1-9991-1986c571ef8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-9.877554</td>\n",
       "      <td>-3.336145</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-7.287210</td>\n",
       "      <td>-8.353986</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-6.943061</td>\n",
       "      <td>-7.023744</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-7.440167</td>\n",
       "      <td>-8.791959</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6.641388</td>\n",
       "      <td>-8.075888</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  group\n",
       "0  -9.877554  -3.336145      0\n",
       "1  -7.287210  -8.353986      2\n",
       "2  -6.943061  -7.023744      2\n",
       "3  -7.440167  -8.791959      2\n",
       "4  -6.641388  -8.075888      2"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make simulated feature matrix\n",
    "features, _ = make_blobs(n_samples = 50,\n",
    "                         n_features = 2,\n",
    "                         centers = 3,\n",
    "                         random_state = 1)\n",
    "\n",
    "# Create DataFrame\n",
    "dataframe = pd.DataFrame(features, columns=[\"feature_1\", \"feature_2\"])\n",
    "\n",
    "# Make k-means clusterer\n",
    "clusterer = KMeans(3, random_state=0)\n",
    "\n",
    "# Fit clusterer\n",
    "clusterer.fit(features)\n",
    "\n",
    "# Predict values\n",
    "dataframe[\"group\"] = clusterer.predict(features)\n",
    "\n",
    "# View first few observations\n",
    "dataframe.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ecd3f2-a696-44ce-92bd-e77a9ca1fe6b",
   "metadata": {},
   "source": [
    "### 4.10 Deleting Observations with Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "7eab811b-a3aa-4c71-9fb3-4822eb4bc9dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.1, 11.1],\n",
       "       [ 2.2, 22.2],\n",
       "       [ 3.3, 33.3],\n",
       "       [ 4.4, 44.4]])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create feature matrix\n",
    "features = np.array([[1.1, 11.1],\n",
    "                     [2.2, 22.2],\n",
    "                     [3.3, 33.3],\n",
    "                     [4.4, 44.4],\n",
    "                     [np.nan, 55]])\n",
    "\n",
    "# Keep only observations that are not (denoted by ~) missing\n",
    "features[~np.isnan(features).any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9789dea8-913c-4ed1-9284-ffe57426c5c6",
   "metadata": {},
   "source": [
    "drop missing observations using pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "0a628263-b63d-4329-83c2-a8b5fce91f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1</td>\n",
       "      <td>11.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.2</td>\n",
       "      <td>22.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.3</td>\n",
       "      <td>33.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.4</td>\n",
       "      <td>44.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2\n",
       "0        1.1       11.1\n",
       "1        2.2       22.2\n",
       "2        3.3       33.3\n",
       "3        4.4       44.4"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "dataframe = pd.DataFrame(features, columns=[\"feature_1\", \"feature_2\"])\n",
    "\n",
    "# Remove observations with missing values\n",
    "dataframe.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea653008-a2f5-44bb-a5ae-efea1b6d6637",
   "metadata": {},
   "source": [
    "## 5. Handling Categorical Data\n",
    "It is often useful to measure objects not in terms of their quantity but in terms of\n",
    "some quality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c05e9c8-3979-4e39-ab3c-a5b3f9007a1b",
   "metadata": {},
   "source": [
    "### 5.1 Encoding Nominal Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74f35a86-5d09-466d-b9f4-2d35af1e4abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create feature\n",
    "feature = np.array([[\"Texas\"],\n",
    "                    [\"California\"],\n",
    "                    [\"Texas\"],\n",
    "                    [\"Delaware\"],\n",
    "                    [\"Texas\"]])\n",
    "\n",
    "# Create one-hot encoder\n",
    "one_hot = LabelBinarizer()\n",
    "\n",
    "# One-hot encode feature\n",
    "one_hot.fit_transform(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "764035dd-0a93-4907-a45e-3e06ae008ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['California', 'Delaware', 'Texas'], dtype='<U10')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View feature classes\n",
    "one_hot.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8591e25-e3fe-40a9-89e1-f8a2fab3abd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>California</th>\n",
       "      <th>Delaware</th>\n",
       "      <th>Texas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   California  Delaware  Texas\n",
       "0           0         0      1\n",
       "1           1         0      0\n",
       "2           0         0      1\n",
       "3           0         1      0\n",
       "4           0         0      1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe\n",
    "df_one_hot = pd.DataFrame(one_hot.fit_transform(feature), \n",
    "                  columns=one_hot.classes_)\n",
    "\n",
    "df_one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7ba72d-0320-4b17-bf94-e4b511ef43be",
   "metadata": {},
   "source": [
    "If we want to reverse the one-hot encoding, we can use `inverse_transform`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5366d17a-53f4-4eb3-ab1b-74d01c696b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Texas', 'California', 'Texas', 'Delaware', 'Texas'], dtype='<U10')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reverse one-hot encoding\n",
    "one_hot.inverse_transform(one_hot.transform(feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22080226-783e-473d-8e64-1329b34a6fa9",
   "metadata": {},
   "source": [
    "We can even use pandas to one-hot encode the feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "833ed55d-c491-43a5-983d-b4846534a05c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>California</th>\n",
       "      <th>Delaware</th>\n",
       "      <th>Texas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   California  Delaware  Texas\n",
       "0           0         0      1\n",
       "1           1         0      0\n",
       "2           0         0      1\n",
       "3           0         1      0\n",
       "4           0         0      1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dummy variables from feature\n",
    "pd.get_dummies(feature.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0bc9bb-e26a-4f4f-891d-160fdf63be0f",
   "metadata": {},
   "source": [
    "One helpful ability of scikit-learn is to handle a situation where each observation lists\n",
    "multiple classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "333827c9-b683-4af9-b53e-997677113a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 1],\n",
       "       [1, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 1],\n",
       "       [0, 0, 1, 1, 0],\n",
       "       [1, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create multiclass feature\n",
    "multiclass_feature = [(\"Texas\", \"Florida\"),\n",
    "                      (\"California\", \"Alabama\"),\n",
    "                      (\"Texas\", \"Florida\"),\n",
    "                      (\"Delware\", \"Florida\"),\n",
    "                      (\"Texas\", \"Alabama\")]\n",
    "\n",
    "# Create multiclass one-hot encoder\n",
    "one_hot_multiclass = MultiLabelBinarizer()\n",
    "\n",
    "# One-hot encode multiclass feature\n",
    "one_hot_multiclass.fit_transform(multiclass_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c81ca4-0f04-4a30-a313-598f227a7d97",
   "metadata": {},
   "source": [
    "### 5.2 Encoding Ordinal Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3fa36ef6-0599-4086-a9b2-4ee659cf3c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    2\n",
       "3    2\n",
       "4    3\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create features\n",
    "dataframe = pd.DataFrame({\"Score\": [\"Low\", \"Low\", \"Medium\", \"Medium\", \"High\"]})\n",
    "\n",
    "# Create mapper\n",
    "scale_mapper = {\"Low\":1,\n",
    "                \"Medium\":2,\n",
    "                \"High\":3}\n",
    "\n",
    "# Replace feature values with scale\n",
    "dataframe[\"Score\"].replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c981cadd-5939-4bd0-841e-7e1364d171d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    2\n",
       "3    2\n",
       "4    4\n",
       "5    3\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.DataFrame({\"Score\": [\"Low\",\n",
    "                                    \"Low\",\n",
    "                                    \"Medium\",\n",
    "                                    \"Medium\",\n",
    "                                    \"High\",\n",
    "                                    \"Barely More Than Medium\"]})\n",
    "\n",
    "scale_mapper = {\"Low\":1,\n",
    "                 \"Medium\":2,\n",
    "                 \"Barely More Than Medium\": 3,\n",
    "                 \"High\":4}\n",
    "\n",
    "dataframe[\"Score\"].replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9994805-64d6-4441-a974-eae1e57d739d",
   "metadata": {},
   "source": [
    "In this example, the distance between Low and Medium is the same as the distance\n",
    "between Medium and Barely More Than Medium, which is almost certainly not accurate. The best approach is to be conscious about the numerical values mapped to\n",
    "classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d3a0e49-dcdc-48b1-86fb-0ae6c1369317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    1.0\n",
       "2    2.0\n",
       "3    2.0\n",
       "4    3.0\n",
       "5    2.1\n",
       "Name: Score, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_mapper = {\"Low\":1,\n",
    "                 \"Medium\":2,\n",
    "                 \"Barely More Than Medium\": 2.1,\n",
    "                 \"High\":3}\n",
    "\n",
    "dataframe[\"Score\"].replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdaec73-9255-4703-8328-f46b3e9fd772",
   "metadata": {},
   "source": [
    "### 5.3 Encoding Dictionaries of Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f1ac91ba-28ed-4403-bf65-224f271ca0c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4., 2., 0.],\n",
       "       [3., 4., 0.],\n",
       "       [0., 1., 2.],\n",
       "       [0., 2., 2.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dictionary\n",
    "data_dict = [{\"Red\": 2, \"Blue\": 4},\n",
    "             {\"Red\": 4, \"Blue\": 3},\n",
    "             {\"Red\": 1, \"Yellow\": 2},\n",
    "             {\"Red\": 2, \"Yellow\": 2}]\n",
    "\n",
    "# Create object dictionary vectorizer\n",
    "dictvectorizer = DictVectorizer(sparse=False)\n",
    "\n",
    "# Convert dictionary to feature matrix\n",
    "features = dictvectorizer.fit_transform(data_dict)\n",
    "\n",
    "# View feature matrix\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359ea653-902d-4db2-b2d0-bb77d42532df",
   "metadata": {},
   "source": [
    "We can get the names of each generated feature using the get_feature_names\n",
    "method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e561682a-4605-4ad8-8185-33ef574170c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Blue', 'Red', 'Yellow'], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get feature names\n",
    "feature_names = dictvectorizer.get_feature_names_out()\n",
    "\n",
    "# View feature names\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "35c0241e-19e6-4774-b596-7345bb15145d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Blue</th>\n",
       "      <th>Red</th>\n",
       "      <th>Yellow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Blue  Red  Yellow\n",
       "0     4    2       0\n",
       "1     3    4       0\n",
       "2     0    1       2\n",
       "3     0    2       2"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe to view te output better\n",
    "pd.DataFrame(features, columns=feature_names).astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "54747c5f-b53d-41c4-a2ba-5a4d8796279e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4., 2., 0.],\n",
       "       [3., 4., 0.],\n",
       "       [0., 1., 2.],\n",
       "       [0., 2., 2.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create word counts dictionaries for four documents\n",
    "doc_1_word_count = {\"Red\": 2, \"Blue\": 4}\n",
    "doc_2_word_count = {\"Red\": 4, \"Blue\": 3}\n",
    "doc_3_word_count = {\"Red\": 1, \"Yellow\": 2}\n",
    "doc_4_word_count = {\"Red\": 2, \"Yellow\": 2}\n",
    "\n",
    "# Create list\n",
    "doc_word_counts = [doc_1_word_count,\n",
    "                    doc_2_word_count,\n",
    "                    doc_3_word_count,\n",
    "                    doc_4_word_count]\n",
    "\n",
    "# Convert list of word count dictionaries into feature matrix\n",
    "dictvectorizer.fit_transform(doc_word_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945a2342-4a46-4695-b1b9-dc9aa60ab19b",
   "metadata": {},
   "source": [
    "### 5.4 Imputing Missing Class Values\n",
    "**Problem**<br>\n",
    "You have a categorical feature containing missing values that you want to replace with\n",
    "predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cb269690-e650-40e6-b1ed-70c73fafaf9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  0.87,  1.31],\n",
       "       [ 1.  , -0.67, -0.22],\n",
       "       [ 0.  ,  2.1 ,  1.45],\n",
       "       [ 1.  ,  1.18,  1.33],\n",
       "       [ 0.  ,  1.22,  1.27],\n",
       "       [ 1.  , -0.21, -1.19]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create feature matrix with categorical feature\n",
    "X = np.array([[0, 2.10, 1.45],\n",
    "              [1, 1.18, 1.33],\n",
    "              [0, 1.22, 1.27],\n",
    "              [1, -0.21, -1.19]]) \n",
    "\n",
    "# Create feature matrix with missing values in the categorical feature\n",
    "X_with_nan = np.array([[np.nan, 0.87, 1.31],\n",
    "                       [np.nan, -0.67, -0.22]])\n",
    "\n",
    "# Train KNN learner\n",
    "clf = KNeighborsClassifier(3, weights='distance')\n",
    "trained_model = clf.fit(X[:,1:], X[:,0])\n",
    "\n",
    "# Predict missing values' class\n",
    "imputed_values = trained_model.predict(X_with_nan[:,1:])\n",
    "\n",
    "# Join column of predicted class with their other features\n",
    "X_with_imputed = np.hstack((imputed_values.reshape(-1,1), X_with_nan[:,1:]))\n",
    "\n",
    "# Join two feature matrices\n",
    "np.vstack((X_with_imputed, X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436971b6-ac2d-4507-8a74-02af64e16283",
   "metadata": {},
   "source": [
    "An alternative solution is to fill in missing values with the feature’s most frequent\n",
    "value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "10acdf1b-642e-4876-8a4d-ea91bb648183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  0.87,  1.31],\n",
       "       [ 0.  , -0.67, -0.22],\n",
       "       [ 0.  ,  2.1 ,  1.45],\n",
       "       [ 1.  ,  1.18,  1.33],\n",
       "       [ 0.  ,  1.22,  1.27],\n",
       "       [ 1.  , -0.21, -1.19]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join the two feature matrices\n",
    "X_complete = np.vstack((X_with_nan, X))\n",
    "\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "imputer.fit_transform(X_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fb1771-a4bc-4ae1-850c-8f0a3252368a",
   "metadata": {},
   "source": [
    "### 5.5 Handling Imbalanced Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a6abda77-7620-47f7-b125-7b4be81b68bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load iris data\n",
    "iris = load_iris()\n",
    "\n",
    "# Create feature matrix\n",
    "features = iris.data\n",
    "\n",
    "# Create target vector\n",
    "target = iris.target\n",
    "\n",
    "# Remove first 40 observations\n",
    "features = features[40:,:]\n",
    "target = target[40:]\n",
    "\n",
    "# Create binary target vector indicating if class 0\n",
    "target = np.where((target == 0), 0, 1)\n",
    "\n",
    "# Look at the imbalanced target vector\n",
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0b0c69-08ab-4e94-b5cd-62101e967e38",
   "metadata": {},
   "source": [
    "Many algorithms in scikit-learn offer a parameter to weight classes during training to\n",
    "counteract the effect of their imbalance. While we have not covered it yet, RandomFor\n",
    "estClassifier is a popular classification algorithm and includes a class_weight\n",
    "parameter. You can pass an argument specifying the desired class weights explicitly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4ee15bdb-d598-428f-9370-0af01d068a9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight={0: 0.9, 1: 0.1})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create weights\n",
    "weights = {0: .9, 1: 0.1}\n",
    "\n",
    "# Create random forest classifier with weights\n",
    "RandomForestClassifier(class_weight=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ff3719-c8c8-412e-9f94-7f4a88982844",
   "metadata": {},
   "source": [
    "Or you can pass balanced, which automatically creates weights inversely propor‐\n",
    "tional to class frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c32b58d5-1cc8-4d73-885f-8e0bb9f381ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a random forest with balanced class weights\n",
    "RandomForestClassifier(class_weight=\"balanced\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e26dd89-8466-497c-8fd1-0466c3dbe12f",
   "metadata": {},
   "source": [
    "Alternatively, we can downsample the majority class or upsample the minority class.\n",
    "In downsampling, we randomly sample without replacement from the majority class\n",
    "(i.e., the class with more observations) to create a new subset of observations equal in\n",
    "size to the minority class. For example, if the minority class has 10 observations, we\n",
    "will randomly select 10 observations from the majority class and use those 20 obser‐\n",
    "vations as our data. Here we do exactly that using our unbalanced Iris data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d046ed4e-4de2-46b9-95b1-a9fbe2a5f022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indicies of each class' observations\n",
    "i_class0 = np.where(target == 0)[0]\n",
    "i_class1 = np.where(target == 1)[0]\n",
    "\n",
    "# Number of observations in each class\n",
    "n_class0 = len(i_class0)\n",
    "n_class1 = len(i_class1)\n",
    "\n",
    "# For every observation of class 0, randomly sample\n",
    "# from class 1 without replacement\n",
    "i_class1_downsampled = np.random.choice(i_class1, size=n_class0, replace=False)\n",
    "\n",
    "# Join together class 0's target vector with the\n",
    "# downsampled class 1's target vector\n",
    "np.hstack((target[i_class0], target[i_class1_downsampled]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5933c424-a4a8-46cd-8a4c-862d92c9afa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.1, 2.5, 3. , 1.1]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join together class 0's feature matrix with the\n",
    "# downsampled class 1's feature matrix\n",
    "np.vstack((features[i_class0,:], features[i_class1_downsampled,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "26ea918b-997e-4027-9915-3451ce96e89a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For every observation in class 1, randomly sample from class 0 with replacement\n",
    "i_class0_upsampled = np.random.choice(i_class0, size=n_class1, replace=True)\n",
    "\n",
    "# Join together class 0's upsampled target vector with class 1's target vector\n",
    "np.concatenate((target[i_class0_upsampled], target[i_class1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "48a3f3f8-b706-4190-b381-d74d348768d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.6, 3.2, 1.4, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [4.4, 3.2, 1.3, 0.2]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join together class 0's upsampled feature matrix with class 1's feature matrix\n",
    "np.vstack((features[i_class0_upsampled,:], features[i_class1,:]))[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35367d79-b7cb-401f-9b48-7d793dfd2d08",
   "metadata": {},
   "source": [
    "Downsampling and upsampling. In downsampling we create a random subset of the majority class of equal size to the minority\n",
    "class. In upsampling we repeatedly sample with replacement from the minority class\n",
    "to make it of equal size as the majority class. The decision between using downsampling and upsampling is context-specific, and in general we should try both to see\n",
    "which produces better results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08ae8ff-8b93-4f86-b266-5890654112b1",
   "metadata": {},
   "source": [
    "## 6. Handling Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7392a91f-7b18-4ee4-bf3d-c71ae819ecff",
   "metadata": {},
   "source": [
    "Unstructured text data, like the contents of a book or a tweet, is both one of the most\n",
    "interesting sources of features and one of the most complex to handle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b520858b-dfb9-4318-b5a0-dc3005f26675",
   "metadata": {},
   "source": [
    "### 6.1 Cleaning Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "16286ab2-d1b5-4a32-b934-a1f1437e6109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Interrobang. By Aishwarya Henriette',\n",
       " 'Parking And Going. By Karl Gautier',\n",
       " 'Today Is The night. By Jarek Prakash']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create text\n",
    "text_data = [\" Interrobang. By Aishwarya Henriette \",\n",
    "             \"Parking And Going. By Karl Gautier\",\n",
    "             \" Today Is The night. By Jarek Prakash \"]\n",
    "\n",
    "# Strip whitespaces\n",
    "strip_whitespace = [string.strip() for string in text_data]\n",
    "\n",
    "# Show text\n",
    "strip_whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1670c210-12ac-49b1-9adb-3f6a2751dee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Interrobang By Aishwarya Henriette',\n",
       " 'Parking And Going By Karl Gautier',\n",
       " 'Today Is The night By Jarek Prakash']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove periods\n",
    "remove_periods = [string.replace(\".\", \"\") for string in strip_whitespace]\n",
    "\n",
    "remove_periods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8876446-c0a8-4cc6-9eb5-a4772e1fcdf5",
   "metadata": {},
   "source": [
    "We also create and apply a custom transformation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "03259d6c-cc98-4064-bdf3-9c787ae55178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['INTERROBANG BY AISHWARYA HENRIETTE',\n",
       " 'PARKING AND GOING BY KARL GAUTIER',\n",
       " 'TODAY IS THE NIGHT BY JAREK PRAKASH']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create function\n",
    "capitalizer = lambda x: x.upper()\n",
    "\n",
    "# Apply function\n",
    "[capitalizer(string) for string in remove_periods]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a404f6-5786-4fa6-a89a-ca3ff21e3eed",
   "metadata": {},
   "source": [
    "Finally, we can use regular expressions to make powerful string operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "32301d23-9428-4140-b329-247dddddd5c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['XXXXXXXXXXX XX XXXXXXXXX XXXXXXXXX',\n",
       " 'XXXXXXX XXX XXXXX XX XXXX XXXXXXX',\n",
       " 'XXXXX XX XXX XXXXX XX XXXXX XXXXXXX']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create function\n",
    "def replace_letters_with_X(string: str) -> str:\n",
    "    return re.sub(r\"[a-zA-Z]\", \"X\", string)\n",
    "\n",
    "# Apply function\n",
    "[replace_letters_with_X(string) for string in remove_periods]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b8093f-6ae5-441a-9520-2005fe7443e5",
   "metadata": {},
   "source": [
    "### 6.2 Parsing and Cleaning HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6105028a-4940-4363-a269-8c95a5f35047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Masego Azra'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create some HTML code\n",
    "\n",
    "html = \"<div class='full_name'><span style='font-weight:bold'>Masego</span> Azra</div>\"\n",
    "\n",
    "# Parse html\n",
    "soup = BeautifulSoup(html, \"lxml\")\n",
    "\n",
    "# Find the div with the class \"full_name\", show text\n",
    "soup.find(\"div\", { \"class\" : \"full_name\" }).text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c413d99-2f7d-4dff-ab76-9874a4ab0e7c",
   "metadata": {},
   "source": [
    "### 6.3 Menghilangkan Tanda Baca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "43f1d9d2-be53-43e3-afd2-01832f09cba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi I Love This Song', '10000 Agree LoveIT', 'Right']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create text\n",
    "text_data = ['Hi!!!! I. Love. This. Song....',\n",
    "             '10000% Agree!!!! #LoveIT',\n",
    "             'Right?!?!']\n",
    "\n",
    "# Create a dictionary of punctuation characters\n",
    "punctuation = dict.fromkeys(i for i in range(sys.maxunicode)\n",
    "                            if unicodedata.category(chr(i)).startswith('P'))\n",
    "\n",
    "# For each string, remove any punctuation characters\n",
    "[string.translate(punctuation) for string in text_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad220067-918c-4f23-b9db-ef21b19e95f5",
   "metadata": {},
   "source": [
    "### 6.4 Tokenizing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3cbe1c72-e02c-4f90-a9e7-cadc6ae14301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'science', 'of', 'today', 'is', 'the', 'technology', 'of', 'tomorrow']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create text\n",
    "string = \"The science of today is the technology of tomorrow\"\n",
    "\n",
    "# Tokenize words\n",
    "word_tokenize(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dbaa90-a59c-435b-aaa1-b68c1438edfc",
   "metadata": {},
   "source": [
    "We can also tokenize into sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9ac845e3-3619-4381-a5e0-eee649a8677d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The science of today is the technology of tomorrow.', 'Tomorrow is today.']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create text\n",
    "string = \"The science of today is the technology of tomorrow. Tomorrow is today.\"\n",
    "\n",
    "# Tokenize sentences\n",
    "sent_tokenize(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32563ba6-69fd-4dc1-b7f4-3171e0c5396e",
   "metadata": {},
   "source": [
    "### 6.5 Removing Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d075aa78-7f16-43f5-928d-5f1e9ebe550b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['going', 'go', 'store', 'park']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create word tokens\n",
    "tokenized_words  =  ['i',\n",
    "                     'am',\n",
    "                     'going',\n",
    "                     'to',\n",
    "                     'go',\n",
    "                     'to',\n",
    "                     'the',\n",
    "                     'store',\n",
    "                     'and',\n",
    "                     'park']\n",
    "\n",
    "# Load stop words\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# Remove stop words\n",
    "[word for word in tokenized_words if word not in stop_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdaadc09-9552-4ed5-838b-ccf86cd7a4de",
   "metadata": {},
   "source": [
    "While “stop words” can refer to any set of words we want to remove before process‐\n",
    "ing, frequently the term refers to extremely common words that themselves contain\n",
    "little information value. NLTK has a list of common stop words that we can use to\n",
    "find and remove stop words in our tokenized words:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0c83c2-824b-489f-940d-6b859bceb143",
   "metadata": {},
   "source": [
    "### 6.6 Stemming Words (kata dasar)\n",
    "You have tokenized words and want to convert them into their root forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "711500c1-afbc-4961-9593-f28b74241ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'am', 'humbl', 'by', 'thi', 'tradit', 'meet']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create word tokens\n",
    "tokenized_words = ['i', 'am', 'humbled', 'by', 'this', 'traditional', 'meeting']\n",
    "\n",
    "# Create stemmer\n",
    "porter = PorterStemmer()\n",
    "\n",
    "# Apply stemmer\n",
    "[porter.stem(word) for word in tokenized_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47ca126-5039-4e57-9049-3e796f975c29",
   "metadata": {},
   "source": [
    "### 6.7 Tagging Parts of Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fdc2b06d-c53f-4013-9124-9bc7695fb8ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Chris', 'NNP'), ('loved', 'VBD'), ('outdoor', 'RP'), ('running', 'VBG')]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create text\n",
    "text_data = \"Chris loved outdoor running\"\n",
    "\n",
    "# Use pre-trained part of speech tagger\n",
    "text_tagged = pos_tag(word_tokenize(text_data))\n",
    "\n",
    "# Show parts\n",
    "text_tagged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6daf709-ad78-4ece-ab24-9c46e9f1078e",
   "metadata": {},
   "source": [
    "<img src='spech.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c666a6-e128-4238-a58d-5a0dd848ec7f",
   "metadata": {},
   "source": [
    "Once the text has been tagged, we can use the tags to find certain parts of speech. For\n",
    "example, here are all nouns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e6117e49-0af0-4363-9080-5f67e09430f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chris']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter words\n",
    "[word for word, tag in text_tagged if tag in ['NN','NNS','NNP','NNPS'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5515319f-7fd4-4a47-a227-37a196f5c9f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 1, 0, 1, 1, 1, 0],\n",
       "       [1, 0, 1, 1, 0, 0, 0, 0, 1],\n",
       "       [1, 0, 1, 1, 1, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create text\n",
    "tweets = [\"I am eating a burrito for breakfast\",\n",
    "          \"Political science is an amazing field\",\n",
    "          \"San Francisco is an awesome city\"]\n",
    "\n",
    "# Create list\n",
    "tagged_tweets = []\n",
    "\n",
    "# Tag each word and each tweet\n",
    "for tweet in tweets:\n",
    "    tweet_tag = nltk.pos_tag(word_tokenize(tweet))\n",
    "    tagged_tweets.append([tag for word, tag in tweet_tag])\n",
    "    \n",
    "# Use one-hot encoding to convert the tags into features\n",
    "one_hot_multi = MultiLabelBinarizer()\n",
    "one_hot_multi.fit_transform(tagged_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0e6ce89e-d7e1-41b9-9719-d5c64cc1bf52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['DT', 'IN', 'JJ', 'NN', 'NNP', 'PRP', 'VBG', 'VBP', 'VBZ'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show feature names\n",
    "one_hot_multi.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3f35f0-5b38-4baf-9609-ee18bfd28601",
   "metadata": {},
   "source": [
    "### 6.8 Encoding Text as a Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "08d5b82a-44cc-404b-a9b6-11144b511746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 2, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 1, 0, 1],\n",
       "       [1, 0, 1, 0, 1, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create text\n",
    "text_data = np.array(['I love Brazil. Brazil!',\n",
    "                      'Sweden is best',\n",
    "                      'Germany beats both']) \n",
    "\n",
    "# Create the bag of words feature matrix\n",
    "count = CountVectorizer()\n",
    "bag_of_words = count.fit_transform(text_data)\n",
    "\n",
    "# Show feature matrix\n",
    "bag_of_words.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f0854fb6-7bb5-44ca-99ed-cdb7aaada92b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['beats', 'best', 'both', 'brazil', 'germany', 'is', 'love',\n",
       "       'sweden'], dtype=object)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the word associated with each feature\n",
    "count.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "49b4465d-7cbe-4a93-af2c-3fc5dc4c622b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beats</th>\n",
       "      <th>best</th>\n",
       "      <th>both</th>\n",
       "      <th>brazil</th>\n",
       "      <th>germany</th>\n",
       "      <th>is</th>\n",
       "      <th>love</th>\n",
       "      <th>sweden</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   beats  best  both  brazil  germany  is  love  sweden\n",
       "0      0     0     0       2        0   0     1       0\n",
       "1      0     1     0       0        0   1     0       1\n",
       "2      1     0     1       0        1   0     0       0"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_words = pd.DataFrame(bag_of_words.toarray(),\n",
    "                        columns=count.get_feature_names_out())\n",
    "\n",
    "df_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5a70d35c-acee-4826-a5d7-66375f2f6c20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [0],\n",
       "       [0]], dtype=int64)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create feature matrix with arguments\n",
    "count_2gram = CountVectorizer(ngram_range=(1,2),\n",
    "                              stop_words=\"english\",\n",
    "                              vocabulary=['brazil'])\n",
    "\n",
    "bag = count_2gram.fit_transform(text_data)\n",
    "\n",
    "# View feature matrix\n",
    "bag.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "553ae2ce-f7c1-41dc-89f5-107da7fd3fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'brazil': 0}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the 1-grams and 2-grams\n",
    "count_2gram.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbbe229-1abb-46a1-969f-591f01608fdc",
   "metadata": {},
   "source": [
    "### 6.8 Weighting Word Importance\n",
    "**Problem**<br>\n",
    "You want a bag of words, but with words weighted by their importance to an observa‐\n",
    "tion.<br><br>\n",
    "**Solution**<br>\n",
    "Compare the frequency of the word in a document (a tweet, movie review, speech\n",
    "transcript, etc.) with the frequency of the word in all other documents using term\n",
    "frequency-inverse document frequency (tf-idf). scikit-learn makes this easy with\n",
    "`TfidfVectorizer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0b7d2bbc-e897-4208-93d0-8ec763e5e7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3)\t0.8944271909999159\n",
      "  (0, 6)\t0.4472135954999579\n",
      "  (1, 1)\t0.5773502691896257\n",
      "  (1, 5)\t0.5773502691896257\n",
      "  (1, 7)\t0.5773502691896257\n",
      "  (2, 2)\t0.5773502691896257\n",
      "  (2, 0)\t0.5773502691896257\n",
      "  (2, 4)\t0.5773502691896257\n"
     ]
    }
   ],
   "source": [
    "# Create text\n",
    "text_data = np.array(['I love Brazil. Brazil!',\n",
    "                      'Sweden is best',\n",
    "                      'Germany beats both'])\n",
    "# Create the tf-idf feature matrix\n",
    "tfidf = TfidfVectorizer()\n",
    "feature_matrix = tfidf.fit_transform(text_data)\n",
    "\n",
    "# Show tf-idf feature matrix\n",
    "print(feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0036902a-3a56-4388-b5f2-9fbd70e652ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'love': 6,\n",
       " 'brazil': 3,\n",
       " 'sweden': 7,\n",
       " 'is': 5,\n",
       " 'best': 1,\n",
       " 'germany': 4,\n",
       " 'beats': 0,\n",
       " 'both': 2}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocabulary_ shows us the word of each feature\n",
    "tfidf.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0284b949-8a14-4704-a349-a665a644982d",
   "metadata": {},
   "source": [
    "## 7. Handling Dates and Times\n",
    "cooming soon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205efb5a-fc2b-4e99-9aba-1847fd1a87b8",
   "metadata": {},
   "source": [
    "## 9. Dimensionality Reduction Using Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9191df-7251-478d-8bcd-a8774a4691c1",
   "metadata": {},
   "source": [
    "## 11. Model Evaluation\n",
    "Models\n",
    "are only as useful as the quality of their predictions, and thus fundamentally our goal\n",
    "is not to create models (which is easy) but to create high-quality models (which is\n",
    "hard)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb74b09-ed3e-4d1d-8da0-b1f93cba2e0d",
   "metadata": {},
   "source": [
    "### 11.1 Cross-Validating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74184db9-314a-4b64-b34e-aa63fa228680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9693916821849783"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load digits datasets\n",
    "digits = load_digits()\n",
    "\n",
    "# Create features matrix\n",
    "features = digits.data\n",
    "\n",
    "# Create target vector\n",
    "target = digits.target\n",
    "\n",
    "# Create standardizer\n",
    "standardizer = StandardScaler()\n",
    "\n",
    "# Create logistic regression object\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Create a pipeline that standardizes, then runs logistic regression\n",
    "pipeline = make_pipeline(standardizer, logreg)\n",
    "\n",
    "# Create k-Fold cross-validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "# Conduct k-fold cross-validation\n",
    "cv_results = cross_val_score(pipeline, # Pipeline\n",
    "                             features, # Feature matrix\n",
    "                             target, # Target vector\n",
    "                             cv=kf, # Cross-validation technique\n",
    "                             scoring=\"accuracy\", # Loss function\n",
    "                             n_jobs=-1) # Use all CPU scores\n",
    "\n",
    "# Calculate mean\n",
    "cv_results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3057bd8-ee6e-4a1c-8c69-45089e5a1bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97777778, 0.98888889, 0.96111111, 0.94444444, 0.97777778,\n",
       "       0.98333333, 0.95555556, 0.98882682, 0.97765363, 0.93854749])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View score for all 10 folds\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cdebd02-d5f8-43ea-b4b8-ee18f603c265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and test sets\n",
    "X_train, X_test, target_train, target_test = train_test_split(features, \n",
    "                                                              target, \n",
    "                                                              test_size=0.1, \n",
    "                                                              random_state=1)\n",
    "\n",
    "# Fit standardizer to training set\n",
    "standardizer.fit(X_train)\n",
    "\n",
    "# Apply to both training and test sets\n",
    "features_train_std = standardizer.transform(X_train)\n",
    "features_test_std = standardizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a01b226-1865-4b89-be21-eaf9c66bc0e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9641285177517063"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a pipeline\n",
    "pipeline = make_pipeline(standardizer, logreg)\n",
    "\n",
    "# Do k-fold cross-validation\n",
    "cv_results = cross_val_score(pipeline, # Pipeline\n",
    "                             features_train_std, # Feature matrix\n",
    "                             y_train, # Target vector\n",
    "                             cv=kf, # Cross-validation technique\n",
    "                             scoring=\"accuracy\", # Loss function\n",
    "                             n_jobs=-1) # Use all CPU scores\n",
    "cv_results.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4993c2-68ba-4fc2-997b-a6cbee2871ae",
   "metadata": {},
   "source": [
    "`n_jobs=-1` tells scikit-learn to use every core available. For example, if your\n",
    "computer has four cores (a common number for laptops), then scikit-learn will use\n",
    "all four cores at once to speed up the operation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f77d80b-b16c-45f7-9a83-c75a1650b196",
   "metadata": {},
   "source": [
    "### 11.2 Creating a Baseline Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6675ae35-8316-43e3-a838-8c0811f632cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.001119359203955339"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "boston = load_boston()\n",
    "\n",
    "# Create features and target\n",
    "features, target = boston.data, boston.target\n",
    "\n",
    "# Make test and training split\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, \n",
    "    target, \n",
    "    random_state=0)\n",
    "\n",
    "# Create a dummy regressor\n",
    "dummy = DummyRegressor(strategy='mean')\n",
    "\n",
    "# \"Train\" dummy regressor\n",
    "dummy.fit(features_train, target_train)\n",
    "\n",
    "# Get R-squared score\n",
    "dummy.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c503305-1d40-42e6-80e6-7de265be9a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6354638433202144"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train simple linear regression model\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(features_train, target_train)\n",
    "\n",
    "# Get R-squared score\n",
    "linreg.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660372e0-286e-49c5-810f-cafb2458eb7e",
   "metadata": {},
   "source": [
    "DummyRegressor memungkinkan kita untuk membuat model yang sangat sederhana yang dapat kita gunakan sebagai baseline\n",
    "untuk membandingkan dengan model kami yang sebenarnya. Ini sering berguna untuk mensimulasikan \"naif\"\n",
    "proses prediksi yang ada dalam suatu produk atau sistem. Misalnya, suatu produk mungkin\n",
    "awalnya telah di-hardcode untuk mengasumsikan bahwa semua pengguna baru akan menghabiskan $100 di\n",
    "bulan pertama, terlepas dari fitur mereka. Jika kita mengkodekan asumsi itu ke dalam garis dasar\n",
    "model, kami dapat secara konkret menyatakan manfaat menggunakan pendekatan pembelajaran mesin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec17d32b-186e-45ff-92bc-189c4ce09545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.06510502029325727"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dummy regressor that predicts 20's for everything\n",
    "clf = DummyRegressor(strategy='constant', constant=20)\n",
    "clf.fit(features_train, target_train)\n",
    "\n",
    "# Evaluate score\n",
    "clf.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d953c237-ec76-4249-9a7e-7a1e2df06f21",
   "metadata": {},
   "source": [
    "Semakin dekat R2 ke 1, semakin banyak varians dalam vektor target yang dijelaskan oleh\n",
    "fitur-fitur."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f03cf03-0470-42e9-9e24-7bc1ddf9da1b",
   "metadata": {},
   "source": [
    "### 11.3 Creating a Baseline Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7ab402f-4727-4539-a22b-56a71782a1ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42105263157894735"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "iris = load_iris()\n",
    "\n",
    "# Create target vector and feature matrix\n",
    "features, target = iris.data, iris.target\n",
    "\n",
    "# Split into training and test set\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, \n",
    "    target, \n",
    "    random_state=0)\n",
    "\n",
    "# Create dummy classifier\n",
    "dummy = DummyClassifier(strategy='uniform', random_state=1)\n",
    "\n",
    "# \"Train\" model\n",
    "dummy.fit(features_train, target_train)\n",
    "\n",
    "# Get accuracy score\n",
    "dummy.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbebe8cc-a9cf-48fb-bf6b-8328d29200f4",
   "metadata": {},
   "source": [
    "By comparing the baseline classifier to our trained classifier, we can see the improve‐\n",
    "ment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d4edf7b-69b2-446e-960c-f770bbd72a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load library\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create classifier\n",
    "classifier = RandomForestClassifier()\n",
    "\n",
    "# Train model\n",
    "classifier.fit(features_train, target_train)\n",
    "\n",
    "# Get accuracy score\n",
    "classifier.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960c8fb4-863a-4e56-b9db-5eb5b93544ba",
   "metadata": {},
   "source": [
    "### 11.4 Evaluating Binary Classifier Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b897a845-5f8c-4cec-bd35-3470a8581f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9550999999999998"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate features matrix and target vector\n",
    "X, y = make_classification(n_samples = 10000,\n",
    "                           n_features = 3,\n",
    "                           n_informative = 3,\n",
    "                           n_redundant = 0,\n",
    "                           n_classes = 2,\n",
    "                           random_state = 1)\n",
    "\n",
    "# Create logistic regression\n",
    "logit = LogisticRegression()\n",
    "\n",
    "# Cross-validate model using accuracy\n",
    "accuracy = cross_val_score(logit, X, y, scoring=\"accuracy\")\n",
    "\n",
    "accuracy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "185d542e-3851-4dbf-8dfc-2ddbcc5fd396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9587098102922853"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-validate model using precision\n",
    "precision = cross_val_score(logit, X, y, scoring=\"precision\")\n",
    "\n",
    "precision.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bf5e2f-bda7-43f2-9ddb-e038d075af9a",
   "metadata": {},
   "source": [
    "*Presisi memberi tahu kita jika kita telah memprediksi hasil positif, seberapa besar kita yakin itu akan benar-benar positif*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9d96368-5024-408f-be23-71fdf952dcb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9511999999999998"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-validate model using recall\n",
    "recall = cross_val_score(logit, X, y, scoring=\"recall\")\n",
    "\n",
    "recall.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a87ed5f-7c1f-41c9-8098-206f676015fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.954931376985931"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-validate model using f1\n",
    "f1 = cross_val_score(logit, X, y, scoring=\"f1\")\n",
    "\n",
    "f1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64fa809b-ff31-46a3-9908-df027f92bf26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.947"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create training and test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.1,\n",
    "                                                    random_state=1)\n",
    "\n",
    "# Predict values for training target vector\n",
    "y_hat = logit.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9711ac42-5f72-4835-bbf0-5c51607802cd",
   "metadata": {},
   "source": [
    "### 11.5 Evaluating Binary Classifier Thresholds\n",
    "evaluate a binary classifier and various probability thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a5b2f289-ff4d-4355-a293-c19d1d79f018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature matrix and target vector\n",
    "features, target = make_classification(n_samples=10000,\n",
    "                                        n_features=10,\n",
    "                                        n_classes=2,\n",
    "                                        n_informative=3,\n",
    "                                        random_state=3)\n",
    "\n",
    "# Split into training and test sets\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "     features, target, test_size=0.1, random_state=1)\n",
    "\n",
    "# Create classifier\n",
    "logit = LogisticRegression()\n",
    "\n",
    "# Train model\n",
    "logit.fit(features_train, target_train)\n",
    "\n",
    "# Get predicted probabilities\n",
    "target_probabilities = logit.predict_proba(features_test)[:,1]\n",
    "\n",
    "# Create true and false positive rates\n",
    "false_positive_rate, true_positive_rate, threshold = roc_curve(target_test,\n",
    "                                                                target_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e53074c7-817c-4721-adc6-b4e56d9c020c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot ROC curve\n",
    "plt.title(\"Receiver Operating Characteristic\")\n",
    "plt.plot(false_positive_rate, true_positive_rate)\n",
    "plt.plot([0, 1], ls=\"--\")\n",
    "plt.plot([0, 0], [1, 0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fa7be294-0f59-490d-9c37-2fb8d79b0af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.86891533, 0.13108467]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get predicted probabilities\n",
    "logit.predict_proba(features_test)[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f217eb7f-21d1-4091-83b3-3fa34792f3a5",
   "metadata": {},
   "source": [
    "In this example, the first observation has an ~87% chance of being in the negative\n",
    "class (0) and a 13% chance of being in the positive class (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "514b1bd9-e721-414b-918b-928dbf53ec30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the class\n",
    "logit.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639303e2-e9be-4528-b5b2-65f638c29955",
   "metadata": {},
   "source": [
    "The ROC curve represents the respective TPR and FPR for every probability thres‐\n",
    "hold. For example, in our solution a threshold of roughly 0.50 has a TPR of \\0.81 and an\n",
    "FPR of \\0.15:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d1fa917d-a6b6-4633-bbfa-dcd2715472a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.5331715230155316\n",
      "True Positive Rate: 0.810204081632653\n",
      "False Positive Rate: 0.14901960784313725\n"
     ]
    }
   ],
   "source": [
    "print(\"Threshold:\", threshold[116])\n",
    "print(\"True Positive Rate:\", true_positive_rate[116])\n",
    "print(\"False Positive Rate:\", false_positive_rate[116])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd4b84c-60ae-4f89-8623-51001e63e78e",
   "metadata": {},
   "source": [
    "However, if we increase the threshold to ~80% (i.e., increase how certain the model\n",
    "has to be before it predicts an observation as positive) the TPR drops significantly but\n",
    "so does the FPR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d71cbf82-0085-4efc-8a20-624316678637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.8189133876659292\n",
      "True Positive Rate: 0.5448979591836735\n",
      "False Positive Rate: 0.047058823529411764\n"
     ]
    }
   ],
   "source": [
    "print(\"Threshold:\", threshold[45])\n",
    "print(\"True Positive Rate:\", true_positive_rate[45])\n",
    "print(\"False Positive Rate:\", false_positive_rate[45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fdc2de73-5a61-46c6-99eb-1412aaba5668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9073389355742297"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate area under curve\n",
    "roc_auc_score(target_test, target_probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40703bbb-29c1-45e2-86ab-b145be4e10f0",
   "metadata": {},
   "source": [
    "semakin besar nilai AUC maka pengklasifikasian semakin baik\n",
    "* AUC = 0 -> BURUK\n",
    "* AUC = 1 -> BAIK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9991db3f-cf1c-4b4b-b0f1-84f117f4705d",
   "metadata": {},
   "source": [
    "### 11.6 Evaluating Multiclass Classifier Predictions\n",
    "You have a model that predicts three or more classes and want to evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a64f7ee6-5682-4505-823e-fa499238b74c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.841 , 0.829 , 0.8265, 0.8155, 0.82  ])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate features matrix and target vector\n",
    "features, target = make_classification(n_samples = 10000,\n",
    "                                         n_features = 3,\n",
    "                                         n_informative = 3,\n",
    "                                         n_redundant = 0,\n",
    "                                         n_classes = 3,\n",
    "                                         random_state = 1)\n",
    "\n",
    "# Create logistic regression\n",
    "logit = LogisticRegression()\n",
    "\n",
    "# Cross-validate model using accuracy\n",
    "cross_val_score(logit, features, target, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39cdc5e9-b191-4112-a6fc-dcf9792ec8ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84061272, 0.82895312, 0.82625661, 0.81515121, 0.81992692])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-validate model using macro averaged F1 score\n",
    "cross_val_score(logit, features, target, scoring='f1_macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcbaadf-8789-47b3-899e-146d29937de2",
   "metadata": {},
   "source": [
    "* **makro** = Hitung rata-rata skor metrik untuk setiap kelas, dengan bobot masing-masing kelas sama.<br>\n",
    "* **weighted** =\n",
    "Hitung rata-rata skor metrik untuk setiap kelas, bobot setiap kelas proporsional\n",
    "dengan ukurannya dalam data.<br>\n",
    "* **mikro** = \n",
    "Hitung rata-rata skor metrik untuk setiap kombinasi kelas observasi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e194ecc4-c358-434a-ab95-ea5781f01c48",
   "metadata": {},
   "source": [
    "### 11.7 Visualizing a Classifier’s Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "373f5eb4-1d18-4d1a-854d-83e5ed851098",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load data\n",
    "iris = load_iris()\n",
    "\n",
    "# Create feature and target\n",
    "features, target = iris.data, iris.target\n",
    "\n",
    "# Create list of target class names\n",
    "class_names = iris.target_names\n",
    "\n",
    "# Create training and test set\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, random_state=1)\n",
    "\n",
    "# Create logistic regression\n",
    "classifier = LogisticRegression()\n",
    "\n",
    "# Train model and make predictions\n",
    "target_predicted = classifier.fit(features_train, target_train).predict(features_test)\n",
    "\n",
    "# Create confusion matrix\n",
    "matrix = confusion_matrix(target_test, target_predicted)\n",
    "\n",
    "# Create pandas dataframe\n",
    "dataframe = pd.DataFrame(matrix, index=class_names, columns=class_names)\n",
    "\n",
    "# Create heatmap\n",
    "sns.heatmap(dataframe, annot=True, cbar=None, cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.ylabel(\"True Class\")\n",
    "plt.xlabel(\"Predicted Class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7117bdf0-3c71-4bab-845f-30406d68001c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13,  0,  0],\n",
       "       [ 0, 15,  1],\n",
       "       [ 0,  0,  9]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69cfc20-fef7-48a4-ad18-56515db6b80a",
   "metadata": {},
   "source": [
    "### 11.8 Evaluating Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d5844f4c-c338-4994-bbc6-d4d749ad7ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1974.65337976, -2004.54137625, -3935.19355723, -1060.04361386,\n",
       "       -1598.74104702])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate features matrix, target vector\n",
    "features, target = make_regression(n_samples = 100,\n",
    "                                     n_features = 3,\n",
    "                                     n_informative = 3,\n",
    "                                     n_targets = 1,\n",
    "                                     noise = 50,\n",
    "                                     coef = False,\n",
    "                                     random_state = 1)\n",
    "\n",
    "# Create a linear regression object\n",
    "ols = LinearRegression()\n",
    "\n",
    "# Cross-validate the linear regression using (negative) MSE\n",
    "cross_val_score(ols, features, target, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13e53f6b-9943-453b-b518-d961772001cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8622399 , 0.85838075, 0.74723548, 0.91354743, 0.84469331])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-validate the linear regression using R-squared\n",
    "cross_val_score(ols, features, target, scoring='r2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107fe16f-7324-4c8a-9f5e-14a9e9545054",
   "metadata": {},
   "source": [
    "MSE is a\n",
    "measurement of the squared sum of all distances between predicted and true values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0b074a-aca3-4153-9bab-8b82af629aae",
   "metadata": {},
   "source": [
    "### 11.9 Evaluating Clustering Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fdde027f-4d95-4159-a797-d699467f19b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8916265564072142"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate feature matrix\n",
    "features, _ = make_blobs(n_samples = 1000,\n",
    "                         n_features = 10,\n",
    "                         centers = 2,\n",
    "                         cluster_std = 0.5,\n",
    "                         shuffle = True,\n",
    "                         random_state = 1)\n",
    "\n",
    "# Cluster data using k-means to predict classes\n",
    "model = KMeans(n_clusters=2, random_state=1).fit(features)\n",
    "\n",
    "# Get predicted classes\n",
    "target_predicted = model.labels_\n",
    "\n",
    "# Evaluate model\n",
    "silhouette_score(features, target_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471a1f13-5428-487a-a2c3-4db802093d63",
   "metadata": {},
   "source": [
    "<img src='shiloute.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce8fc53-b8d1-4ac7-bcb5-0884eeb67301",
   "metadata": {},
   "source": [
    "### 11.10 Creating a Custom Evaluation Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb30132e-139a-495c-864b-dfc5e5aa478d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9997906102882058"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate features matrix and target vector\n",
    "features, target = make_regression(n_samples = 100,\n",
    "                                   n_features = 3,\n",
    "                                   random_state = 1)\n",
    "\n",
    "# Create training set and test set\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.10, random_state=1)\n",
    "\n",
    "# Create custom metric\n",
    "def custom_metric(target_test, target_predicted):\n",
    "    # Calculate r-squared score\n",
    "    r2 = r2_score(target_test, target_predicted)\n",
    "    # Return r-squared score\n",
    "    return r2\n",
    "\n",
    "# Make scorer and define that higher scores are better\n",
    "score = make_scorer(custom_metric, greater_is_better=True)\n",
    "\n",
    "# Create ridge regression object\n",
    "classifier = Ridge()\n",
    "\n",
    "# Train ridge regression model\n",
    "model = classifier.fit(features_train, target_train)\n",
    "\n",
    "# Apply custom scorer\n",
    "score(model, features_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07df2fe3-f031-46ce-8e50-3debfabdfaeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9997906102882058"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict values\n",
    "target_predicted = model.predict(features_test)\n",
    "\n",
    "# Calculate r-squared score\n",
    "r2_score(target_test, target_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9078429a-dd8f-43d7-bf0a-ae041d4a3c94",
   "metadata": {},
   "source": [
    "### 11.11 Visualizing the Effect of Training Set Size\n",
    "evaluate the effect of the number of observations in your training set on\n",
    "some metric (accuracy, F1, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2718423c-a24c-494e-9a6b-06fd374934e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "digits = load_digits()\n",
    "\n",
    "# Create feature matrix and target vector\n",
    "features, target = digits.data, digits.target\n",
    "\n",
    "# Create CV training and test scores for various training set sizes\n",
    "train_sizes, train_scores, test_scores = learning_curve(# Classifier\n",
    "                                                        RandomForestClassifier(),\n",
    "                                                        # Feature matrix\n",
    "                                                        features,\n",
    "                                                        # Target vector\n",
    "                                                        target,\n",
    "                                                        # Number of folds\n",
    "                                                        cv=10,\n",
    "                                                        # Performance metric\n",
    "                                                        scoring='accuracy',\n",
    "                                                        # Use all computer cores\n",
    "                                                        n_jobs=-1,\n",
    "                                                        # Sizes of 50\n",
    "                                                        # training set\n",
    "                                                        train_sizes=np.linspace(0.01, 1.0, 50))\n",
    "\n",
    "\n",
    "# Create means and standard deviations of training set scores\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "\n",
    "# Create means and standard deviations of test set scores\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7612922d-5cac-4513-bcf3-ffba35529224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Draw lines\n",
    "plt.plot(train_sizes, train_mean, '--', color=\"#111111\", label=\"Training score\")\n",
    "plt.plot(train_sizes, test_mean, color=\"#111111\", label=\"Cross-validation score\")\n",
    "\n",
    "# Draw bands\n",
    "plt.fill_between(train_sizes, train_mean - train_std,\n",
    "                 train_mean + train_std, color=\"#DDDDDD\")\n",
    "plt.fill_between(train_sizes, test_mean - test_std,\n",
    "                 test_mean + test_std, color=\"#DDDDDD\")\n",
    "\n",
    "# Create plot\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.xlabel(\"Training Set Size\"), plt.ylabel(\"Accuracy Score\"),\n",
    "plt.legend(loc=\"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015a8fcf-b457-4d4c-bc5f-fdc68647dac6",
   "metadata": {},
   "source": [
    "### 11.12 Creating a Text Report of Evaluation Metrics\n",
    "quick description of a classifier’s performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9eb27f7a-8a5d-447a-8395-52be2d3ca0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        13\n",
      "  versicolor       1.00      0.94      0.97        16\n",
      "   virginica       0.90      1.00      0.95         9\n",
      "\n",
      "    accuracy                           0.97        38\n",
      "   macro avg       0.97      0.98      0.97        38\n",
      "weighted avg       0.98      0.97      0.97        38\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "iris = load_iris()\n",
    "\n",
    "# Create feature matrix\n",
    "features = iris.data\n",
    "\n",
    "# Create target vector\n",
    "target = iris.target\n",
    "\n",
    "# Create list of target class names\n",
    "class_names = iris.target_names\n",
    "\n",
    "# Create training and test set\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "     features, target, random_state=1)\n",
    "\n",
    "# Create logistic regression\n",
    "classifier = LogisticRegression()\n",
    "\n",
    "# Train model and make predictions\n",
    "model = classifier.fit(features_train, target_train)\n",
    "target_predicted = model.predict(features_test)\n",
    "\n",
    "# Create a classification report\n",
    "print(classification_report(target_test,\n",
    "                            target_predicted,\n",
    "                            target_names=class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c25bec5-999d-4d17-a5dc-a7dda7c92085",
   "metadata": {},
   "source": [
    "### 11.13 Visualizing the Effect of Hyperparameter Values\n",
    "want to understand how the performance of a model changes as the value of\n",
    "some hyperparameter changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "05c1f5a6-e14b-4d25-bd11-3fafba6084be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "digits = load_digits()\n",
    "\n",
    "# Create feature matrix and target vector\n",
    "features, target = digits.data, digits.target\n",
    "\n",
    "# Create range of values for parameter\n",
    "param_range = np.arange(1, 250, 2)\n",
    "\n",
    "# Calculate accuracy on training and test set using range of parameter values\n",
    "train_scores, test_scores = validation_curve(\n",
    "                                             # Classifier\n",
    "                                             RandomForestClassifier(),\n",
    "                                             # Feature matrix\n",
    "                                             features,\n",
    "                                             # Target vector\n",
    "                                             target,\n",
    "                                             # Hyperparameter to examine\n",
    "                                             param_name=\"n_estimators\",\n",
    "                                             # Range of hyperparameter's values\n",
    "                                             param_range=param_range,\n",
    "                                             # Number of folds\n",
    "                                             cv=3,\n",
    "                                             # Performance metric\n",
    "                                             scoring=\"accuracy\",\n",
    "                                             # Use all computer cores\n",
    "                                             n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "589f0416-5668-4756-a379-7fa137dca1f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate mean and standard deviation for training set scores\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "\n",
    "# Calculate mean and standard deviation for test set scores\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "# Plot mean accuracy scores for training and test sets\n",
    "plt.plot(param_range, train_mean, label=\"Training score\", color=\"black\")\n",
    "plt.plot(param_range, test_mean, label=\"Cross-validation score\", color=\"dimgrey\")\n",
    "\n",
    "# Plot accurancy bands for training and test sets\n",
    "plt.fill_between(param_range, train_mean - train_std,\n",
    "     train_mean + train_std, color=\"gray\")\n",
    "plt.fill_between(param_range, test_mean - test_std,\n",
    "     test_mean + test_std, color=\"gainsboro\")\n",
    "\n",
    "# Create plot\n",
    "plt.title(\"Validation Curve With Random Forest\")\n",
    "plt.xlabel(\"Number Of Trees\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.tight_layout()\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a982502a-dd9f-4df1-838c-080cf24b1e96",
   "metadata": {},
   "source": [
    "## 12. Model Selection\n",
    "In machine learning, we use training algorithms to learn the parameters of a model\n",
    "by minimizing some loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fd7ae9-3b2e-468a-8bd8-1a6f9243ef68",
   "metadata": {},
   "source": [
    "### 12.1 Selecting Best Models Using Exhaustive Search\n",
    "select the best model by searching over a range of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7016186-6af7-4acc-8bd8-e32a184fdf49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "50 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.97333333        nan 0.97333333        nan 0.98\n",
      "        nan 0.98              nan 0.98              nan 0.98\n",
      "        nan 0.97333333        nan 0.97333333        nan 0.97333333\n",
      "        nan 0.97333333]\n",
      "  warnings.warn(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "iris = load_iris()\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "\n",
    "# Create logistic regression\n",
    "logistic = LogisticRegression()\n",
    "\n",
    "# Create range of candidate penalty hyperparameter values\n",
    "penalty = ['l1', 'l2']\n",
    "\n",
    "# Create range of candidate regularization hyperparameter values\n",
    "C = np.logspace(0, 4, 10)\n",
    "\n",
    "# Create dictionary hyperparameter candidates\n",
    "hyperparameters = dict(C=C, penalty=penalty)\n",
    "\n",
    "# Create grid search\n",
    "gridsearch = GridSearchCV(logistic, hyperparameters, cv=5, verbose=0)\n",
    "\n",
    "# Fit grid search\n",
    "best_model = gridsearch.fit(features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309260d1-9653-4584-bd60-45f0bdf20545",
   "metadata": {},
   "source": [
    "Once GridSearchCV is complete, we can see the hyperparameters of the best model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f57a12d-369b-4514-bf41-e4b40fa78acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Penalty: l2\n",
      "Best C: 7.742636826811269\n"
     ]
    }
   ],
   "source": [
    "# View best hyperparameters\n",
    "print('Best Penalty:', best_model.best_estimator_.get_params()['penalty'])\n",
    "print('Best C:', best_model.best_estimator_.get_params()['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "340383aa-0d27-4878-9692-600fdf0ab8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict target vector\n",
    "best_model.predict(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fe183a-d06e-4b9c-b2f2-e3347acdf387",
   "metadata": {},
   "source": [
    "### 12.2 Selecting Best Models Using Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85309ff9-e8fe-4db1-bca3-386a9b6bea7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "230 fits failed out of a total of 500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "230 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.97333333 0.97333333 0.96666667 0.96666667 0.97333333\n",
      "        nan        nan        nan        nan 0.97333333 0.97333333\n",
      "        nan 0.97333333 0.97333333 0.96              nan        nan\n",
      " 0.94666667        nan 0.96       0.97333333        nan 0.97333333\n",
      "        nan 0.97333333 0.97333333 0.97333333 0.97333333 0.96666667\n",
      " 0.97333333        nan        nan 0.97333333        nan        nan\n",
      " 0.97333333 0.97333333        nan        nan 0.96       0.97333333\n",
      "        nan        nan        nan 0.97333333 0.97333333 0.97333333\n",
      "        nan 0.97333333        nan        nan 0.97333333        nan\n",
      " 0.97333333        nan        nan        nan        nan        nan\n",
      " 0.96666667        nan        nan        nan        nan 0.97333333\n",
      "        nan        nan 0.97333333 0.97333333        nan        nan\n",
      " 0.97333333 0.96              nan        nan 0.96       0.97333333\n",
      " 0.97333333 0.97333333 0.94666667        nan 0.97333333 0.97333333\n",
      " 0.97333333        nan 0.97333333        nan 0.97333333 0.97333333\n",
      " 0.96666667 0.97333333        nan 0.97333333        nan        nan\n",
      "        nan 0.97333333 0.97333333 0.97333333]\n",
      "  warnings.warn(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "iris = load_iris()\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "\n",
    "# Create logistic regression\n",
    "logistic = LogisticRegression()\n",
    "\n",
    "# Create range of candidate regularization penalty hyperparameter values\n",
    "penalty = ['l1', 'l2']\n",
    "\n",
    "# Create distribution of candidate regularization hyperparameter values\n",
    "C = uniform(loc=0, scale=4)\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(C=C, penalty=penalty)\n",
    "\n",
    "# Create randomized search\n",
    "randomizedsearch = RandomizedSearchCV(logistic, \n",
    "                                      hyperparameters, \n",
    "                                      random_state=1, \n",
    "                                      n_iter=100, \n",
    "                                      cv=5, \n",
    "                                      verbose=0,\n",
    "                                      n_jobs=-1)\n",
    "\n",
    "# Fit randomized search\n",
    "best_model = randomizedsearch.fit(features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be3590e-ba5e-4cba-b78a-eaa39f4d697a",
   "metadata": {},
   "source": [
    "With RandomizedSearchCV, if we specify a distribution, scikit-learn will randomly\n",
    "sample without replacement hyperparameter values from that distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7da4de4-836c-4a66-bfe9-3930e62dd5c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.14929308, 0.61946033, 3.16224352, 2.14911885, 1.86795879,\n",
       "       1.72715271, 3.37815269, 1.88820134, 3.48979884, 1.51215279])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a uniform distribution between 0 and 4, sample 10 values\n",
    "uniform(loc=0, scale=4).rvs(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f88b06-7441-4a44-ad25-867f1a46c2e8",
   "metadata": {},
   "source": [
    "Alternatively, if we specify a list of values such as two regularization penalty hyper‐\n",
    "parameter values, ['l1', 'l2'], RandomizedSearchCV will randomly sample with\n",
    "replacement from the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fadbd1c6-3eb6-458f-82c4-54d1ab5e4fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Penalty: l2\n",
      "Best C: 3.730229437354635\n"
     ]
    }
   ],
   "source": [
    "# View best hyperparameters\n",
    "print('Best Penalty:', best_model.best_estimator_.get_params()['penalty'])\n",
    "print('Best C:', best_model.best_estimator_.get_params()['C'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd98ab8-71b0-491c-a05b-fd5f5eb8a30e",
   "metadata": {},
   "source": [
    "### 12.3 Selecting Best Models from Multiple Learning Algorithms\n",
    "select the best model by searching over a range of learning algorithms\n",
    "and their respective hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "357a7ede-e639-417b-a11c-9dcf1a2c86f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "50 fits failed out of a total of 145.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.97333333        nan 0.97333333        nan 0.98\n",
      "        nan 0.98              nan 0.98              nan 0.98\n",
      "        nan 0.97333333        nan 0.97333333        nan 0.97333333\n",
      "        nan 0.97333333 0.95333333 0.96       0.95333333 0.95333333\n",
      " 0.96666667 0.96666667 0.96       0.96       0.96      ]\n",
      "  warnings.warn(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "np.random.seed(0)\n",
    "\n",
    "# Load data\n",
    "iris = load_iris()\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "\n",
    "# Create a pipeline\n",
    "pipe = Pipeline([(\"classifier\", RandomForestClassifier())])\n",
    "\n",
    "# Create dictionary with candidate learning algorithms and their hyperparameters\n",
    "search_space = [{\"classifier\": [LogisticRegression()],\n",
    "                 \"classifier__penalty\": ['l1', 'l2'],\n",
    "                 \"classifier__C\": np.logspace(0, 4, 10)},\n",
    "                 {\"classifier\": [RandomForestClassifier()],\n",
    "                 \"classifier__n_estimators\": [10, 100, 1000],\n",
    "                 \"classifier__max_features\": [1, 2, 3]}]\n",
    "\n",
    "# Create grid search\n",
    "gridsearch = GridSearchCV(pipe, search_space, cv=5, verbose=0)\n",
    "\n",
    "# Fit grid search\n",
    "best_model = gridsearch.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ded85cfb-6cbc-4aa0-8cf4-c2f0a621f23f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=7.742636826811269)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View best model\n",
    "best_model.best_estimator_.get_params()[\"classifier\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa32eed2-9e1e-4ea5-a929-8846b27c97a2",
   "metadata": {},
   "source": [
    "### 12.4 Selecting Best Models When Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a92083c-d417-42a5-a822-f3464c3b1964",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "150 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "150 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.96666667 0.96666667 0.96666667\n",
      "        nan        nan        nan 0.96666667 0.96666667 0.97333333\n",
      "        nan        nan        nan 0.96666667 0.98       0.98\n",
      "        nan        nan        nan 0.97333333 0.98       0.98\n",
      "        nan        nan        nan 0.97333333 0.97333333 0.97333333\n",
      "        nan        nan        nan 0.97333333 0.97333333 0.97333333\n",
      "        nan        nan        nan 0.97333333 0.97333333 0.97333333\n",
      "        nan        nan        nan 0.97333333 0.97333333 0.97333333\n",
      "        nan        nan        nan 0.97333333 0.97333333 0.97333333\n",
      "        nan        nan        nan 0.97333333 0.97333333 0.97333333]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "np.random.seed(0)\n",
    "\n",
    "# Load data\n",
    "iris = load_iris()\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "\n",
    "# Create a preprocessing object that includes StandardScaler features and PCA\n",
    "preprocess = FeatureUnion([(\"std\", StandardScaler()), (\"pca\", PCA())])\n",
    "\n",
    "# Create a pipeline\n",
    "pipe = Pipeline([(\"preprocess\", preprocess),\n",
    "                 (\"classifier\", LogisticRegression())])\n",
    "\n",
    "# Create space of candidate values\n",
    "search_space = [{\"preprocess__pca__n_components\": [1, 2, 3],\n",
    "                 \"classifier__penalty\": [\"l1\", \"l2\"],\n",
    "                 \"classifier__C\": np.logspace(0, 4, 10)}]\n",
    "\n",
    "# Create grid search\n",
    "clf = GridSearchCV(pipe, search_space, cv=5, verbose=0, n_jobs=-1)\n",
    "\n",
    "# Fit grid search\n",
    "best_model = clf.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4612aa83-3736-44af-9cb0-2cede05ac4e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View best model\n",
    "best_model.best_estimator_.get_params()['preprocess__pca__n_components']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc358ceb-77a7-435f-bb68-aa530b0e4ea0",
   "metadata": {},
   "source": [
    "### 12.5 Speeding Up Model Selection with Parallelization\n",
    "You need to speed up model selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c5bf0640-0888-4f4e-816e-063a34949aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2000 candidates, totalling 10000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "5000 fits failed out of a total of 10000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5000 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.97333333        nan ... 0.97333333        nan 0.97333333]\n",
      "  warnings.warn(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "iris = load_iris()\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "\n",
    "# Create logistic regression\n",
    "logistic = LogisticRegression()\n",
    "\n",
    "# Create range of candidate regularization penalty hyperparameter values\n",
    "penalty = [\"l1\", \"l2\"]\n",
    "\n",
    "# Create range of candidate values for C\n",
    "C = np.logspace(0, 4, 1000)\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(C=C, penalty=penalty)\n",
    "\n",
    "# Create grid search\n",
    "gridsearch = GridSearchCV(logistic, hyperparameters, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit grid search\n",
    "best_model = gridsearch.fit(features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017822d0-43f3-484c-b321-29390952a4e3",
   "metadata": {},
   "source": [
    "### 12.6 Speeding Up Model Selection Using AlgorithmSpecific Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b6f92c98-6186-4a2c-8331-0ec0c4b825e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=100)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "iris = load_iris()\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "\n",
    "# Create cross-validated logistic regression\n",
    "logit = LogisticRegressionCV(Cs=100)\n",
    "\n",
    "# Train model\n",
    "logit.fit(features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579147da-032d-4e8b-9ba9-f73f09297193",
   "metadata": {},
   "source": [
    "### 12.7 Evaluating Performance After Model Selection\n",
    "evaluate the performance of a model found through model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3b4c3e2d-1469-4bf6-b440-42a2629b8d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9733333333333334"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "iris = load_iris()\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "\n",
    "# Create logistic regression\n",
    "logistic = LogisticRegression()\n",
    "\n",
    "# Create range of 20 candidate values for C\n",
    "C = np.logspace(0, 4, 20)\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(C=C)\n",
    "\n",
    "# Create grid search\n",
    "gridsearch = GridSearchCV(logistic, hyperparameters, cv=5, n_jobs=-1, verbose=0)\n",
    "\n",
    "# Conduct nested cross-validation and outut the average score\n",
    "cross_val_score(gridsearch, features, target).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b5ce2f-74f5-45d1-bf0f-1bbaf5aced75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
